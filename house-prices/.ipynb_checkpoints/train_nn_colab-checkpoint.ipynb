{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f0OIems8yeOC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBeksYJcMIFC"
   },
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Vs50YAcwMH8Y"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 818 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0        60.0         65.0   8450.0          7.0          5.0     2003.0   \n",
       "1        20.0         80.0   9600.0          6.0          8.0     1976.0   \n",
       "2        60.0         68.0  11250.0          7.0          5.0     2001.0   \n",
       "3        70.0         60.0   9550.0          7.0          5.0     1915.0   \n",
       "4        60.0         84.0  14260.0          8.0          5.0     2000.0   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_New  \\\n",
       "0        2003.0       196.0       706.0         0.0  ...             0   \n",
       "1        1976.0         0.0       978.0         0.0  ...             0   \n",
       "2        2002.0       162.0       486.0         0.0  ...             0   \n",
       "3        1970.0         0.0       216.0         0.0  ...             0   \n",
       "4        2000.0       350.0       655.0         0.0  ...             0   \n",
       "\n",
       "   SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
       "0             0            1                      0                      0   \n",
       "1             0            1                      0                      0   \n",
       "2             0            1                      0                      0   \n",
       "3             0            1                      1                      0   \n",
       "4             0            1                      0                      0   \n",
       "\n",
       "   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "0                     0                     0                     1   \n",
       "1                     0                     0                     1   \n",
       "2                     0                     0                     1   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     1   \n",
       "\n",
       "   SaleCondition_Partial  SalePrice  \n",
       "0                      0   208500.0  \n",
       "1                      0   181500.0  \n",
       "2                      0   223500.0  \n",
       "3                      0   140000.0  \n",
       "4                      0   250000.0  \n",
       "\n",
       "[5 rows x 818 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix_in = \"10\"\n",
    "suffix_out = \"10_nn0_ave_100\"\n",
    "df = pd.read_csv(f'data/preprocessed{suffix_in}.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65wreJSVKU0g"
   },
   "source": [
    "# Define networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NnhjZOaCL9KA"
   },
   "outputs": [],
   "source": [
    "def nn0(num_features):\n",
    "  model = Sequential([\n",
    "      Dense(units=num_features, input_shape=(num_features,), activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "      Dense(units=512, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "      Dense(units=64, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "      Dense(units=1, activation='linear'),\n",
    "  ])\n",
    "  model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8rMp8ezuNdmJ"
   },
   "outputs": [],
   "source": [
    "def nn1(num_features):\n",
    "  model = Sequential([\n",
    "      Dense(units=num_features, input_shape=(num_features,), activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "      Dense(units=512, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "      Dense(units=128, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "      Dense(units=1, activation='linear'),\n",
    "  ])\n",
    "  model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tvu600TBOSX0"
   },
   "outputs": [],
   "source": [
    "def nn2(num_features):\n",
    "  model = Sequential([\n",
    "      Dense(units=num_features, input_shape=(num_features,), activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "      Dense(units=512, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "      Dense(units=128, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "      Dense(units=64, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "      Dense(units=1, activation='linear'),\n",
    "  ])\n",
    "  model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "phK-ODYeOAQm"
   },
   "outputs": [],
   "source": [
    "def nn3(num_features):\n",
    "  model = Sequential([\n",
    "      Dense(units=num_features, input_shape=(num_features,), activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "      Dense(units=512, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "      Dense(units=128, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "      Dense(units=64, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "      Dense(units=64, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "      Dense(units=1, activation='linear'),\n",
    "  ])\n",
    "  model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5EsgUUeLLCK"
   },
   "source": [
    "# Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "h4FX0a4sLK2z"
   },
   "outputs": [],
   "source": [
    "class SaveBestModel(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.best = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metric_value = logs['val_mse']\n",
    "        if metric_value < self.best:\n",
    "            self.best = metric_value\n",
    "            self.best_weights= self.model.get_weights()\n",
    "            print(\"\\n*****Saved as Best Model!*****\\n\\n\")\n",
    "\n",
    "class CancelTraining(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, tol=1e-7):\n",
    "        self.last_loss = float('inf')\n",
    "        self.tol = tol\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        loss_delta = abs(logs['val_loss'] - self.last_loss)\n",
    "        if loss_delta < self.tol:\n",
    "            print(\"Model converged. Cancelling training.\")\n",
    "            self.model.stop_training = True\n",
    "        self.last_loss = logs['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5NKZUhK1ymPv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2919, 817), (2919,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:, -1].values\n",
    "X = df.iloc[:, :-1].values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CPW0yGdqrMkf"
   },
   "outputs": [],
   "source": [
    "n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0SJ_LOiUynj8"
   },
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "rwDek3GzyozC"
   },
   "outputs": [],
   "source": [
    "train_idx = 1460\n",
    "X_train, X_test = X[:train_idx], X[train_idx:]\n",
    "y_train, _ = y[:train_idx], y[train_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2lXj3y-HypxL"
   },
   "outputs": [],
   "source": [
    "y_train = np.log(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "lDAn56Wlyqsa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>808</th>\n",
       "      <th>809</th>\n",
       "      <th>810</th>\n",
       "      <th>811</th>\n",
       "      <th>812</th>\n",
       "      <th>813</th>\n",
       "      <th>814</th>\n",
       "      <th>815</th>\n",
       "      <th>816</th>\n",
       "      <th>817</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067331</td>\n",
       "      <td>-0.202068</td>\n",
       "      <td>-0.217879</td>\n",
       "      <td>0.646183</td>\n",
       "      <td>-0.507284</td>\n",
       "      <td>1.046258</td>\n",
       "      <td>0.896833</td>\n",
       "      <td>0.525202</td>\n",
       "      <td>0.580907</td>\n",
       "      <td>-0.29313</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298629</td>\n",
       "      <td>-0.049029</td>\n",
       "      <td>0.394439</td>\n",
       "      <td>-0.263861</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>12.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.873616</td>\n",
       "      <td>0.501870</td>\n",
       "      <td>-0.072044</td>\n",
       "      <td>-0.063185</td>\n",
       "      <td>2.188279</td>\n",
       "      <td>0.154764</td>\n",
       "      <td>-0.395604</td>\n",
       "      <td>-0.572250</td>\n",
       "      <td>1.178112</td>\n",
       "      <td>-0.29313</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298629</td>\n",
       "      <td>-0.049029</td>\n",
       "      <td>0.394439</td>\n",
       "      <td>-0.263861</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>12.109011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067331</td>\n",
       "      <td>-0.061280</td>\n",
       "      <td>0.137197</td>\n",
       "      <td>0.646183</td>\n",
       "      <td>-0.507284</td>\n",
       "      <td>0.980221</td>\n",
       "      <td>0.848965</td>\n",
       "      <td>0.334828</td>\n",
       "      <td>0.097873</td>\n",
       "      <td>-0.29313</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298629</td>\n",
       "      <td>-0.049029</td>\n",
       "      <td>0.394439</td>\n",
       "      <td>-0.263861</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>12.317167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.302568</td>\n",
       "      <td>-0.436714</td>\n",
       "      <td>-0.078385</td>\n",
       "      <td>0.646183</td>\n",
       "      <td>-0.507284</td>\n",
       "      <td>-1.859351</td>\n",
       "      <td>-0.682812</td>\n",
       "      <td>-0.572250</td>\n",
       "      <td>-0.494941</td>\n",
       "      <td>-0.29313</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298629</td>\n",
       "      <td>-0.049029</td>\n",
       "      <td>0.394439</td>\n",
       "      <td>3.789876</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>-2.155466</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>11.849398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067331</td>\n",
       "      <td>0.689587</td>\n",
       "      <td>0.518903</td>\n",
       "      <td>1.355551</td>\n",
       "      <td>-0.507284</td>\n",
       "      <td>0.947203</td>\n",
       "      <td>0.753229</td>\n",
       "      <td>1.387486</td>\n",
       "      <td>0.468931</td>\n",
       "      <td>-0.29313</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298629</td>\n",
       "      <td>-0.049029</td>\n",
       "      <td>0.394439</td>\n",
       "      <td>-0.263861</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>12.429216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 818 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.067331 -0.202068 -0.217879  0.646183 -0.507284  1.046258  0.896833   \n",
       "1 -0.873616  0.501870 -0.072044 -0.063185  2.188279  0.154764 -0.395604   \n",
       "2  0.067331 -0.061280  0.137197  0.646183 -0.507284  0.980221  0.848965   \n",
       "3  0.302568 -0.436714 -0.078385  0.646183 -0.507284 -1.859351 -0.682812   \n",
       "4  0.067331  0.689587  0.518903  1.355551 -0.507284  0.947203  0.753229   \n",
       "\n",
       "        7         8        9    ...       808       809       810       811  \\\n",
       "0  0.525202  0.580907 -0.29313  ... -0.298629 -0.049029  0.394439 -0.263861   \n",
       "1 -0.572250  1.178112 -0.29313  ... -0.298629 -0.049029  0.394439 -0.263861   \n",
       "2  0.334828  0.097873 -0.29313  ... -0.298629 -0.049029  0.394439 -0.263861   \n",
       "3 -0.572250 -0.494941 -0.29313  ... -0.298629 -0.049029  0.394439  3.789876   \n",
       "4  1.387486  0.468931 -0.29313  ... -0.298629 -0.049029  0.394439 -0.263861   \n",
       "\n",
       "        812      813       814       815       816        817  \n",
       "0 -0.064249 -0.09105 -0.126535  0.463937 -0.302693  12.247694  \n",
       "1 -0.064249 -0.09105 -0.126535  0.463937 -0.302693  12.109011  \n",
       "2 -0.064249 -0.09105 -0.126535  0.463937 -0.302693  12.317167  \n",
       "3 -0.064249 -0.09105 -0.126535 -2.155466 -0.302693  11.849398  \n",
       "4 -0.064249 -0.09105 -0.126535  0.463937 -0.302693  12.429216  \n",
       "\n",
       "[5 rows x 818 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "33iiOHFvyrqK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       12.247694\n",
       "1       12.109011\n",
       "2       12.317167\n",
       "3       11.849398\n",
       "4       12.429216\n",
       "          ...    \n",
       "1455    12.072541\n",
       "1456    12.254863\n",
       "1457    12.493130\n",
       "1458    11.864462\n",
       "1459    11.901583\n",
       "Name: target, Length: 1460, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename last column to target\n",
    "df_train.rename(columns={df_train.columns[-1]: 'target'}, inplace=True)\n",
    "df_train[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0POxK67Owcp"
   },
   "source": [
    "# Compare all models for 200 epochs each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZJ1iTytROwM_"
   },
   "outputs": [],
   "source": [
    "def eval_networks(X_train, y_train, models_funcs, n_features, n_epochs=200, n_trials=50):\n",
    "  n_models = len(models_funcs)\n",
    "  results = np.zeros((n_models, n_trials, 4, n_epochs))\n",
    "  weights = [None] * n_models\n",
    "  for model_idx, model_func in enumerate(models_funcs):\n",
    "    for trial in range(n_trials):\n",
    "      model = model_func(n_features)\n",
    "\n",
    "      save_best_model = SaveBestModel()\n",
    "      history = model.fit(X_train, y_train, epochs=n_epochs, validation_split=0.2, callbacks=[save_best_model])\n",
    "      results[model_idx, trial, :, :] = (history.history[\"loss\"], history.history[\"mse\"], history.history[\"val_loss\"], history.history[\"val_mse\"])\n",
    "\n",
    "      if weights[model_idx] is None:\n",
    "        weights[model_idx] = np.array(save_best_model.best_weights) / n_trials\n",
    "      else:\n",
    "        weights[model_idx] = np.array(weights[model_idx]) + np.array(save_best_model.best_weights) / n_trials\n",
    "      del model\n",
    "  return results, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1faspUjETRcS"
   },
   "outputs": [],
   "source": [
    "# models_funcs = [nn0, nn1, nn2, nn3]\n",
    "# models_names = [model_func.__name__ for model_func in models_funcs]\n",
    "\n",
    "# results, _ = eval_networks(X_train, y_train, models_funcs, n_features, n_epochs=200, n_trials=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kh4DA5gDTWdI"
   },
   "source": [
    "# Visualize models performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "hpwuZcgNTWUl"
   },
   "outputs": [],
   "source": [
    "def vis_eval(results, models_names=None):\n",
    "  n_models = results.shape[0]\n",
    "  if models_names is None:\n",
    "    models_names = [\"\"] * n_models\n",
    "\n",
    "  results_ave = results.mean(axis=1)\n",
    "\n",
    "  fig, axes = plt.subplots(nrows=n_models, ncols=2, sharex=True, sharey=True, figsize=(26 , 6 * n_models))\n",
    "  for model_idx in range(n_models):\n",
    "    axes[model_idx, 0].plot(results_ave[model_idx, 0, :], label=\"loss\")\n",
    "    axes[model_idx, 0].plot(results_ave[model_idx, 2, :], label=\"val_loss\")\n",
    "    axes[model_idx, 1].plot(results_ave[model_idx, 1, :], label=\"mse\")\n",
    "    axes[model_idx, 1].plot(results_ave[model_idx, 3, :], label=\"val_mse\")\n",
    "    \n",
    "    axes[model_idx, 0].set_yscale('log')\n",
    "    axes[model_idx, 1].set_yscale('log')\n",
    "    axes[model_idx, 0].grid()\n",
    "    axes[model_idx, 1].grid()\n",
    "\n",
    "    axes[model_idx, 0].title.set_text(models_names[model_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3nD6dWnCdfzu"
   },
   "outputs": [],
   "source": [
    "# vis_eval(results, models_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_ns-qYebbeV"
   },
   "source": [
    "# Retrain the best for longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_Ek8dbqyXWXl"
   },
   "outputs": [],
   "source": [
    "# models_funcs = [nn0, nn3]\n",
    "# models_names = [model_func.__name__ for model_func in models_funcs]\n",
    "\n",
    "# results, weights = eval_networks(X_train, y_train, models_funcs, n_features, n_epochs=800, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "NANceoyoZA1C"
   },
   "outputs": [],
   "source": [
    "# vis_eval(results, models_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ALAijrydpewy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 00:30:16.260434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-19 00:30:16.267014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-19 00:30:16.267390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-19 00:30:16.268085: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-19 00:30:16.268475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-19 00:30:16.268826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-19 00:30:16.269156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-19 00:30:16.682452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-19 00:30:16.682736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-19 00:30:16.682972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-19 00:30:16.683188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3917 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/37 [====================>.........] - ETA: 0s - loss: 38.2635 - mse: 22.7128   \n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 1s 6ms/step - loss: 33.9204 - mse: 18.4446 - val_loss: 21.5371 - val_mse: 6.3745\n",
      "Epoch 2/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 16.9437 - mse: 2.1260\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 16.7174 - mse: 1.9990 - val_loss: 16.8539 - val_mse: 2.6517\n",
      "Epoch 3/400\n",
      "27/37 [====================>.........] - ETA: 0s - loss: 14.8771 - mse: 1.0305\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14.6912 - mse: 0.9756 - val_loss: 14.9213 - val_mse: 1.7406\n",
      "Epoch 4/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13.5621 - mse: 0.8627 - val_loss: 14.2603 - val_mse: 2.0799\n",
      "Epoch 5/400\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12.5497 - mse: 0.6660\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12.3994 - mse: 0.6782 - val_loss: 12.5667 - val_mse: 1.3436\n",
      "Epoch 6/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 11.5889 - mse: 0.8014 - val_loss: 12.1492 - val_mse: 1.8248\n",
      "Epoch 7/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 10.5954 - mse: 0.5928\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10.4900 - mse: 0.5733 - val_loss: 10.5465 - val_mse: 1.0658\n",
      "Epoch 8/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 9.6030 - mse: 0.5117 - val_loss: 10.8228 - val_mse: 2.1395\n",
      "Epoch 9/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 9.0426 - mse: 0.7109 - val_loss: 9.3363 - val_mse: 1.3693\n",
      "Epoch 10/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 8.3723 - mse: 0.7310 - val_loss: 9.5497 - val_mse: 2.2445\n",
      "Epoch 11/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 8.2789 - mse: 1.2579 - val_loss: 8.6335 - val_mse: 1.8931\n",
      "Epoch 12/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 7.7397 - mse: 1.2405 - val_loss: 8.0324 - val_mse: 1.7895\n",
      "Epoch 13/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 6.8022 - mse: 0.7975 - val_loss: 7.1089 - val_mse: 1.3657\n",
      "Epoch 14/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 6.0750 - mse: 0.5613 - val_loss: 6.6446 - val_mse: 1.3752\n",
      "Epoch 15/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 5.7043 - mse: 0.6390 - val_loss: 6.2607 - val_mse: 1.4134\n",
      "Epoch 16/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5.1790 - mse: 0.5237 - val_loss: 6.3057 - val_mse: 1.8461\n",
      "Epoch 17/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.7334 - mse: 0.4550 - val_loss: 5.4201 - val_mse: 1.3278\n",
      "Epoch 18/400\n",
      "28/37 [=====================>........] - ETA: 0s - loss: 4.3260 - mse: 0.3564\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.2831 - mse: 0.3509 - val_loss: 4.7391 - val_mse: 0.9762\n",
      "Epoch 19/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3.9986 - mse: 0.3825 - val_loss: 5.1047 - val_mse: 1.6385\n",
      "Epoch 20/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3.9456 - mse: 0.6068 - val_loss: 5.5611 - val_mse: 2.3521\n",
      "Epoch 21/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.0699 - mse: 0.9662 - val_loss: 4.2522 - val_mse: 1.2469\n",
      "Epoch 22/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3.7585 - mse: 0.8418 - val_loss: 4.7169 - val_mse: 1.8900\n",
      "Epoch 23/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3.5386 - mse: 0.8075 - val_loss: 3.8622 - val_mse: 1.2219\n",
      "Epoch 24/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3.2053 - mse: 0.6442 - val_loss: 3.8884 - val_mse: 1.4195\n",
      "Epoch 25/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 2.9451 - mse: 0.5445\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2.9493 - mse: 0.5634 - val_loss: 3.2366 - val_mse: 0.9369\n",
      "Epoch 26/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2.7542 - mse: 0.5299 - val_loss: 3.3699 - val_mse: 1.2271\n",
      "Epoch 27/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2.6040 - mse: 0.5217 - val_loss: 3.2873 - val_mse: 1.2747\n",
      "Epoch 28/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2.5586 - mse: 0.6051 - val_loss: 2.9001 - val_mse: 1.0073\n",
      "Epoch 29/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2.5254 - mse: 0.6836 - val_loss: 3.0805 - val_mse: 1.2910\n",
      "Epoch 30/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2.6532 - mse: 0.9005 - val_loss: 2.8414 - val_mse: 1.1218\n",
      "Epoch 31/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2.3360 - mse: 0.6602 - val_loss: 3.0413 - val_mse: 1.4162\n",
      "Epoch 32/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2.2565 - mse: 0.6692 - val_loss: 2.5073 - val_mse: 0.9583\n",
      "Epoch 33/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2.0281 - mse: 0.5233 - val_loss: 3.4666 - val_mse: 2.0003\n",
      "Epoch 34/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 2.0001 - mse: 0.5669\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.9726 - mse: 0.5455 - val_loss: 2.1926 - val_mse: 0.8014\n",
      "Epoch 35/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.8065 - mse: 0.4537 - val_loss: 2.6394 - val_mse: 1.3221\n",
      "Epoch 36/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.8290 - mse: 0.5458 - val_loss: 2.1629 - val_mse: 0.9120\n",
      "Epoch 37/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.7555 - mse: 0.5291 - val_loss: 2.2691 - val_mse: 1.0736\n",
      "Epoch 38/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 1.4362 - mse: 0.2686\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.4589 - mse: 0.2977 - val_loss: 1.9080 - val_mse: 0.7831\n",
      "Epoch 39/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.3282 - mse: 0.2376 - val_loss: 1.9262 - val_mse: 0.8688\n",
      "Epoch 40/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.4073 - mse: 0.3790 - val_loss: 2.2434 - val_mse: 1.2453\n",
      "Epoch 41/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.4661 - mse: 0.4862 - val_loss: 1.9573 - val_mse: 0.9988\n",
      "Epoch 42/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.3942 - mse: 0.4500 - val_loss: 2.0193 - val_mse: 1.0884\n",
      "Epoch 43/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.4265 - mse: 0.5144 - val_loss: 1.9740 - val_mse: 1.0803\n",
      "Epoch 44/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.3294 - mse: 0.4524 - val_loss: 2.4179 - val_mse: 1.5607\n",
      "Epoch 45/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.3547 - mse: 0.5045 - val_loss: 1.7386 - val_mse: 0.8941\n",
      "Epoch 46/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.4305 - mse: 0.5962 - val_loss: 2.0374 - val_mse: 1.2098\n",
      "Epoch 47/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.6507 - mse: 0.8254 - val_loss: 2.0910 - val_mse: 1.2647\n",
      "Epoch 48/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.7626 - mse: 0.9333 - val_loss: 2.3392 - val_mse: 1.5131\n",
      "Epoch 49/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.6241 - mse: 0.7745 - val_loss: 2.7160 - val_mse: 1.8598\n",
      "Epoch 50/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 1.2745 - mse: 0.4359\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.2507 - mse: 0.4162 - val_loss: 1.5700 - val_mse: 0.7580\n",
      "Epoch 51/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.0698 - mse: 0.2851 - val_loss: 1.8389 - val_mse: 1.0825\n",
      "Epoch 52/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 1.0849 - mse: 0.3450\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.0510 - mse: 0.3147 - val_loss: 1.4431 - val_mse: 0.7279\n",
      "Epoch 53/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.9879 - mse: 0.2882\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9632 - mse: 0.2662 - val_loss: 1.3922 - val_mse: 0.7096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.0310 - mse: 0.3627 - val_loss: 1.4873 - val_mse: 0.8339\n",
      "Epoch 55/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8342 - mse: 0.1958 - val_loss: 1.4023 - val_mse: 0.7836\n",
      "Epoch 56/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8609 - mse: 0.2540 - val_loss: 1.3575 - val_mse: 0.7641\n",
      "Epoch 57/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8537 - mse: 0.2704 - val_loss: 1.5537 - val_mse: 0.9833\n",
      "Epoch 58/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.8238 - mse: 0.2615\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8084 - mse: 0.2481 - val_loss: 1.2435 - val_mse: 0.6934\n",
      "Epoch 59/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8189 - mse: 0.2790 - val_loss: 1.7194 - val_mse: 1.1893\n",
      "Epoch 60/400\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 0.8033 - mse: 0.2797\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8054 - mse: 0.2830 - val_loss: 1.1009 - val_mse: 0.5871\n",
      "Epoch 61/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8321 - mse: 0.3242 - val_loss: 1.8884 - val_mse: 1.3867\n",
      "Epoch 62/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8635 - mse: 0.3658 - val_loss: 1.2839 - val_mse: 0.7878\n",
      "Epoch 63/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8856 - mse: 0.3928 - val_loss: 1.4188 - val_mse: 0.9275\n",
      "Epoch 64/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8797 - mse: 0.3916 - val_loss: 1.4081 - val_mse: 0.9235\n",
      "Epoch 65/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.0085 - mse: 0.5238 - val_loss: 1.7249 - val_mse: 1.2370\n",
      "Epoch 66/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.0085 - mse: 0.5204 - val_loss: 1.2664 - val_mse: 0.7779\n",
      "Epoch 67/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8586 - mse: 0.3771 - val_loss: 1.3547 - val_mse: 0.8785\n",
      "Epoch 68/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.9640 - mse: 0.4839 - val_loss: 1.2404 - val_mse: 0.7511\n",
      "Epoch 69/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8534 - mse: 0.3670 - val_loss: 1.3267 - val_mse: 0.8447\n",
      "Epoch 70/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.7668 - mse: 0.2934 - val_loss: 1.2639 - val_mse: 0.7995\n",
      "Epoch 71/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6991 - mse: 0.2453 - val_loss: 1.2132 - val_mse: 0.7714\n",
      "Epoch 72/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6401 - mse: 0.2079 - val_loss: 1.0583 - val_mse: 0.6383\n",
      "Epoch 73/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6161 - mse: 0.2040 - val_loss: 1.0182 - val_mse: 0.6163\n",
      "Epoch 74/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.5471 - mse: 0.1517\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5447 - mse: 0.1513 - val_loss: 0.8995 - val_mse: 0.5152\n",
      "Epoch 75/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5075 - mse: 0.1328 - val_loss: 0.9815 - val_mse: 0.6166\n",
      "Epoch 76/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5052 - mse: 0.1471 - val_loss: 0.9910 - val_mse: 0.6396\n",
      "Epoch 77/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5464 - mse: 0.1994 - val_loss: 1.0062 - val_mse: 0.6606\n",
      "Epoch 78/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5787 - mse: 0.2370 - val_loss: 0.8949 - val_mse: 0.5570\n",
      "Epoch 79/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.7181 - mse: 0.3756 - val_loss: 1.0646 - val_mse: 0.7156\n",
      "Epoch 80/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8210 - mse: 0.4694 - val_loss: 1.2713 - val_mse: 0.9152\n",
      "Epoch 81/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.7785 - mse: 0.4188 - val_loss: 1.2340 - val_mse: 0.8693\n",
      "Epoch 82/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6809 - mse: 0.3146 - val_loss: 1.0816 - val_mse: 0.7173\n",
      "Epoch 83/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6307 - mse: 0.2719 - val_loss: 0.9961 - val_mse: 0.6443\n",
      "Epoch 84/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6346 - mse: 0.2822 - val_loss: 1.0746 - val_mse: 0.7240\n",
      "Epoch 85/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6292 - mse: 0.2800 - val_loss: 0.8977 - val_mse: 0.5535\n",
      "Epoch 86/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5541 - mse: 0.2182 - val_loss: 1.0998 - val_mse: 0.7696\n",
      "Epoch 87/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5516 - mse: 0.2269 - val_loss: 0.8615 - val_mse: 0.5375\n",
      "Epoch 88/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5587 - mse: 0.2370 - val_loss: 0.8400 - val_mse: 0.5175\n",
      "Epoch 89/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5510 - mse: 0.2310 - val_loss: 0.8765 - val_mse: 0.5568\n",
      "Epoch 90/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6566 - mse: 0.3299 - val_loss: 1.0284 - val_mse: 0.6922\n",
      "Epoch 91/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8063 - mse: 0.4647 - val_loss: 1.0367 - val_mse: 0.6857\n",
      "Epoch 92/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6497 - mse: 0.2997 - val_loss: 0.9764 - val_mse: 0.6303\n",
      "Epoch 93/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.5436 - mse: 0.2080\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5271 - mse: 0.1934 - val_loss: 0.7259 - val_mse: 0.4031\n",
      "Epoch 94/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5217 - mse: 0.2077 - val_loss: 0.9106 - val_mse: 0.6020\n",
      "Epoch 95/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4778 - mse: 0.1767 - val_loss: 0.8096 - val_mse: 0.5114\n",
      "Epoch 96/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4317 - mse: 0.1398 - val_loss: 0.9081 - val_mse: 0.6241\n",
      "Epoch 97/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4428 - mse: 0.1642 - val_loss: 0.7795 - val_mse: 0.5053\n",
      "Epoch 98/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5330 - mse: 0.2518 - val_loss: 0.9125 - val_mse: 0.6225\n",
      "Epoch 99/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5201 - mse: 0.2292 - val_loss: 0.8257 - val_mse: 0.5287\n",
      "Epoch 100/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4591 - mse: 0.1670 - val_loss: 0.7326 - val_mse: 0.4481\n",
      "Epoch 101/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4773 - mse: 0.1935 - val_loss: 0.9803 - val_mse: 0.6974\n",
      "Epoch 102/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5473 - mse: 0.2677 - val_loss: 0.9897 - val_mse: 0.7053\n",
      "Epoch 103/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.7828 - mse: 0.4754 - val_loss: 0.9738 - val_mse: 0.6371\n",
      "Epoch 104/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.7710 - mse: 0.4266 - val_loss: 1.0492 - val_mse: 0.6993\n",
      "Epoch 105/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.7866 - mse: 0.4448 - val_loss: 1.3813 - val_mse: 1.0454\n",
      "Epoch 106/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.7246 - mse: 0.3877 - val_loss: 0.9381 - val_mse: 0.5999\n",
      "Epoch 107/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8302 - mse: 0.4979 - val_loss: 0.9193 - val_mse: 0.5802\n",
      "Epoch 108/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6574 - mse: 0.3104 - val_loss: 0.9951 - val_mse: 0.6520\n",
      "Epoch 109/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5043 - mse: 0.1764 - val_loss: 0.7548 - val_mse: 0.4399\n",
      "Epoch 110/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4240 - mse: 0.1250 - val_loss: 0.7316 - val_mse: 0.4475\n",
      "Epoch 111/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5980 - mse: 0.3219 - val_loss: 0.7637 - val_mse: 0.4871\n",
      "Epoch 112/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6151 - mse: 0.3194 - val_loss: 0.9057 - val_mse: 0.5991\n",
      "Epoch 113/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5920 - mse: 0.2913 - val_loss: 0.9621 - val_mse: 0.6702\n",
      "Epoch 114/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4394 - mse: 0.1542 - val_loss: 0.8350 - val_mse: 0.5603\n",
      "Epoch 115/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4010 - mse: 0.1349 - val_loss: 0.7804 - val_mse: 0.5245\n",
      "Epoch 116/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3257 - mse: 0.0795 - val_loss: 0.6788 - val_mse: 0.4421\n",
      "Epoch 117/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.2930 - mse: 0.0627\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2924 - mse: 0.0636 - val_loss: 0.6111 - val_mse: 0.3899\n",
      "Epoch 118/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.2591 - mse: 0.0429\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2544 - mse: 0.0395 - val_loss: 0.5660 - val_mse: 0.3570\n",
      "Epoch 119/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2366 - mse: 0.0333 - val_loss: 0.5745 - val_mse: 0.3763\n",
      "Epoch 120/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2340 - mse: 0.0406 - val_loss: 0.5763 - val_mse: 0.3874\n",
      "Epoch 121/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.2271 - mse: 0.0417\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2250 - mse: 0.0402 - val_loss: 0.5114 - val_mse: 0.3310\n",
      "Epoch 122/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2235 - mse: 0.0464 - val_loss: 0.5910 - val_mse: 0.4174\n",
      "Epoch 123/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2232 - mse: 0.0525 - val_loss: 0.5043 - val_mse: 0.3363\n",
      "Epoch 124/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2203 - mse: 0.0557 - val_loss: 0.5176 - val_mse: 0.3551\n",
      "Epoch 125/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2289 - mse: 0.0689 - val_loss: 0.5833 - val_mse: 0.4253\n",
      "Epoch 126/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2527 - mse: 0.0967 - val_loss: 0.5005 - val_mse: 0.3459\n",
      "Epoch 127/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3475 - mse: 0.1901 - val_loss: 0.6122 - val_mse: 0.4498\n",
      "Epoch 128/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3819 - mse: 0.2139 - val_loss: 0.5851 - val_mse: 0.4136\n",
      "Epoch 129/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4704 - mse: 0.2880 - val_loss: 0.7745 - val_mse: 0.5711\n",
      "Epoch 130/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5800 - mse: 0.3604 - val_loss: 0.7567 - val_mse: 0.5286\n",
      "Epoch 131/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3923 - mse: 0.1720 - val_loss: 0.5557 - val_mse: 0.3465\n",
      "Epoch 132/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2807 - mse: 0.0830 - val_loss: 0.5252 - val_mse: 0.3397\n",
      "Epoch 133/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2450 - mse: 0.0682 - val_loss: 0.5009 - val_mse: 0.3331\n",
      "Epoch 134/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.2257 - mse: 0.0628\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2238 - mse: 0.0620 - val_loss: 0.4392 - val_mse: 0.2830\n",
      "Epoch 135/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2120 - mse: 0.0603 - val_loss: 0.4449 - val_mse: 0.2976\n",
      "Epoch 136/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2879 - mse: 0.1388 - val_loss: 0.5238 - val_mse: 0.3662\n",
      "Epoch 137/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3470 - mse: 0.1824 - val_loss: 0.6228 - val_mse: 0.4545\n",
      "Epoch 138/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2788 - mse: 0.1149 - val_loss: 0.5972 - val_mse: 0.4389\n",
      "Epoch 139/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2855 - mse: 0.1295 - val_loss: 0.5885 - val_mse: 0.4303\n",
      "Epoch 140/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3723 - mse: 0.2034 - val_loss: 0.6981 - val_mse: 0.5161\n",
      "Epoch 141/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3650 - mse: 0.1843 - val_loss: 0.5149 - val_mse: 0.3374\n",
      "Epoch 142/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4176 - mse: 0.2408 - val_loss: 0.6730 - val_mse: 0.4902\n",
      "Epoch 143/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4011 - mse: 0.2118 - val_loss: 0.5828 - val_mse: 0.3945\n",
      "Epoch 144/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3590 - mse: 0.1755 - val_loss: 0.4842 - val_mse: 0.3081\n",
      "Epoch 145/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3134 - mse: 0.1459 - val_loss: 0.4771 - val_mse: 0.3157\n",
      "Epoch 146/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.3039 - mse: 0.1430\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2939 - mse: 0.1332 - val_loss: 0.4249 - val_mse: 0.2663\n",
      "Epoch 147/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.2731 - mse: 0.1170\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2732 - mse: 0.1177 - val_loss: 0.4057 - val_mse: 0.2551\n",
      "Epoch 148/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3014 - mse: 0.1464 - val_loss: 0.4815 - val_mse: 0.3248\n",
      "Epoch 149/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2425 - mse: 0.0905 - val_loss: 0.4102 - val_mse: 0.2642\n",
      "Epoch 150/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.1960 - mse: 0.0559\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1956 - mse: 0.0566 - val_loss: 0.3590 - val_mse: 0.2265\n",
      "Epoch 151/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.1690 - mse: 0.0402\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1655 - mse: 0.0377 - val_loss: 0.3274 - val_mse: 0.2041\n",
      "Epoch 152/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.1430 - mse: 0.0228\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1438 - mse: 0.0243 - val_loss: 0.3074 - val_mse: 0.1918\n",
      "Epoch 153/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1364 - mse: 0.0239 - val_loss: 0.3038 - val_mse: 0.1941\n",
      "Epoch 154/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.1318 - mse: 0.0241\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1314 - mse: 0.0241 - val_loss: 0.2794 - val_mse: 0.1748\n",
      "Epoch 155/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1224 - mse: 0.0197 - val_loss: 0.2808 - val_mse: 0.1801\n",
      "Epoch 156/400\n",
      "28/37 [=====================>........] - ETA: 0s - loss: 0.1194 - mse: 0.0204\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1173 - mse: 0.0188 - val_loss: 0.2512 - val_mse: 0.1548\n",
      "Epoch 157/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1197 - mse: 0.0248 - val_loss: 0.3091 - val_mse: 0.2155\n",
      "Epoch 158/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.1249 - mse: 0.0327\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1245 - mse: 0.0325 - val_loss: 0.2230 - val_mse: 0.1317\n",
      "Epoch 159/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1468 - mse: 0.0563 - val_loss: 0.3184 - val_mse: 0.2283\n",
      "Epoch 160/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1508 - mse: 0.0582 - val_loss: 0.2689 - val_mse: 0.1731\n",
      "Epoch 161/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1727 - mse: 0.0764 - val_loss: 0.2999 - val_mse: 0.2028\n",
      "Epoch 162/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1589 - mse: 0.0618 - val_loss: 0.2753 - val_mse: 0.1808\n",
      "Epoch 163/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1361 - mse: 0.0442 - val_loss: 0.2298 - val_mse: 0.1411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1251 - mse: 0.0392 - val_loss: 0.2504 - val_mse: 0.1666\n",
      "Epoch 165/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1226 - mse: 0.0404 - val_loss: 0.2193 - val_mse: 0.1385\n",
      "Epoch 166/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1123 - mse: 0.0327 - val_loss: 0.2572 - val_mse: 0.1786\n",
      "Epoch 167/400\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 0.1073 - mse: 0.0302\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1066 - mse: 0.0298 - val_loss: 0.2066 - val_mse: 0.1311\n",
      "Epoch 168/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0949 - mse: 0.0211 - val_loss: 0.2142 - val_mse: 0.1422\n",
      "Epoch 169/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.0950 - mse: 0.0240\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0949 - mse: 0.0241 - val_loss: 0.1764 - val_mse: 0.1065\n",
      "Epoch 170/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0924 - mse: 0.0235 - val_loss: 0.2049 - val_mse: 0.1371\n",
      "Epoch 171/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.0941 - mse: 0.0267\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0934 - mse: 0.0261 - val_loss: 0.1715 - val_mse: 0.1048\n",
      "Epoch 172/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1099 - mse: 0.0426 - val_loss: 0.1772 - val_mse: 0.1089\n",
      "Epoch 173/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.1127 - mse: 0.0449\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1140 - mse: 0.0463 - val_loss: 0.1688 - val_mse: 0.1016\n",
      "Epoch 174/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1063 - mse: 0.0392 - val_loss: 0.1800 - val_mse: 0.1124\n",
      "Epoch 175/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.1253 - mse: 0.0563\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1337 - mse: 0.0642 - val_loss: 0.1715 - val_mse: 0.0980\n",
      "Epoch 176/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1687 - mse: 0.0878 - val_loss: 0.2823 - val_mse: 0.1936\n",
      "Epoch 177/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2269 - mse: 0.1318 - val_loss: 0.5478 - val_mse: 0.4438\n",
      "Epoch 178/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2877 - mse: 0.1740 - val_loss: 0.2901 - val_mse: 0.1671\n",
      "Epoch 179/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3302 - mse: 0.2012 - val_loss: 0.3436 - val_mse: 0.2092\n",
      "Epoch 180/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4570 - mse: 0.3202 - val_loss: 0.8106 - val_mse: 0.6511\n",
      "Epoch 181/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5948 - mse: 0.3867 - val_loss: 0.6085 - val_mse: 0.3623\n",
      "Epoch 182/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4687 - mse: 0.2327 - val_loss: 0.4493 - val_mse: 0.2336\n",
      "Epoch 183/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3233 - mse: 0.1336 - val_loss: 0.2818 - val_mse: 0.1204\n",
      "Epoch 184/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2233 - mse: 0.0825 - val_loss: 0.3130 - val_mse: 0.1883\n",
      "Epoch 185/400\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 0.1974 - mse: 0.0822\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1891 - mse: 0.0755 - val_loss: 0.1969 - val_mse: 0.0938\n",
      "Epoch 186/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.1322 - mse: 0.0354\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1294 - mse: 0.0337 - val_loss: 0.1661 - val_mse: 0.0768\n",
      "Epoch 187/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1360 - mse: 0.0484 - val_loss: 0.1678 - val_mse: 0.0827\n",
      "Epoch 188/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1336 - mse: 0.0521 - val_loss: 0.1684 - val_mse: 0.0905\n",
      "Epoch 189/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1036 - mse: 0.0297 - val_loss: 0.1653 - val_mse: 0.0953\n",
      "Epoch 190/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.0857 - mse: 0.0182\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0851 - mse: 0.0182 - val_loss: 0.1192 - val_mse: 0.0559\n",
      "Epoch 191/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0721 - mse: 0.0116 - val_loss: 0.1179 - val_mse: 0.0600\n",
      "Epoch 192/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.0674 - mse: 0.0111\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0664 - mse: 0.0103 - val_loss: 0.0993 - val_mse: 0.0450\n",
      "Epoch 193/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0604 - mse: 0.0077 - val_loss: 0.0999 - val_mse: 0.0487\n",
      "Epoch 194/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0560 - mse: 0.0060 - val_loss: 0.0978 - val_mse: 0.0491\n",
      "Epoch 195/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0534 - mse: 0.0057 - val_loss: 0.0920 - val_mse: 0.0451\n",
      "Epoch 196/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.0521 - mse: 0.0061\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0519 - mse: 0.0061 - val_loss: 0.0896 - val_mse: 0.0447\n",
      "Epoch 197/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0501 - mse: 0.0060 - val_loss: 0.0898 - val_mse: 0.0466\n",
      "Epoch 198/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.0481 - mse: 0.0054\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0481 - mse: 0.0055 - val_loss: 0.0839 - val_mse: 0.0420\n",
      "Epoch 199/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0486 - mse: 0.0074 - val_loss: 0.0836 - val_mse: 0.0430\n",
      "Epoch 200/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.0462 - mse: 0.0061\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0462 - mse: 0.0062 - val_loss: 0.0802 - val_mse: 0.0410\n",
      "Epoch 201/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0452 - mse: 0.0064 - val_loss: 0.0944 - val_mse: 0.0563\n",
      "Epoch 202/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0647 - mse: 0.0264 - val_loss: 0.0937 - val_mse: 0.0551\n",
      "Epoch 203/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0568 - mse: 0.0188 - val_loss: 0.1067 - val_mse: 0.0690\n",
      "Epoch 204/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0188 - val_loss: 0.0781 - val_mse: 0.0415\n",
      "Epoch 205/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0531 - mse: 0.0167 - val_loss: 0.0863 - val_mse: 0.0506\n",
      "Epoch 206/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.0450 - mse: 0.0096\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0450 - mse: 0.0097 - val_loss: 0.0711 - val_mse: 0.0362\n",
      "Epoch 207/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0418 - mse: 0.0074 - val_loss: 0.0792 - val_mse: 0.0455\n",
      "Epoch 208/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0393 - mse: 0.0061 - val_loss: 0.0780 - val_mse: 0.0452\n",
      "Epoch 209/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0388 - mse: 0.0065 - val_loss: 0.0710 - val_mse: 0.0392\n",
      "Epoch 210/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0052 - val_loss: 0.0679 - val_mse: 0.0370\n",
      "Epoch 211/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0361 - mse: 0.0056 - val_loss: 0.0665 - val_mse: 0.0363\n",
      "Epoch 212/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0058 - val_loss: 0.0702 - val_mse: 0.0408\n",
      "Epoch 213/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0356 - mse: 0.0064 - val_loss: 0.0716 - val_mse: 0.0429\n",
      "Epoch 214/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0419 - mse: 0.0131 - val_loss: 0.0781 - val_mse: 0.0496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0148 - val_loss: 0.0769 - val_mse: 0.0484\n",
      "Epoch 216/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0422 - mse: 0.0139 - val_loss: 0.0825 - val_mse: 0.0546\n",
      "Epoch 217/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0364 - mse: 0.0088 - val_loss: 0.0684 - val_mse: 0.0411\n",
      "Epoch 218/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0358 - mse: 0.0088 - val_loss: 0.0858 - val_mse: 0.0591\n",
      "Epoch 219/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0337 - mse: 0.0072 - val_loss: 0.0765 - val_mse: 0.0504\n",
      "Epoch 220/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.0330 - mse: 0.0071\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0332 - mse: 0.0073 - val_loss: 0.0568 - val_mse: 0.0312\n",
      "Epoch 221/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0328 - mse: 0.0074 - val_loss: 0.0665 - val_mse: 0.0415\n",
      "Epoch 222/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0367 - mse: 0.0116 - val_loss: 0.0639 - val_mse: 0.0391\n",
      "Epoch 223/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0341 - mse: 0.0094 - val_loss: 0.0613 - val_mse: 0.0366\n",
      "Epoch 224/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0329 - mse: 0.0084 - val_loss: 0.0581 - val_mse: 0.0339\n",
      "Epoch 225/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0306 - mse: 0.0066 - val_loss: 0.0568 - val_mse: 0.0331\n",
      "Epoch 226/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0286 - mse: 0.0052 - val_loss: 0.0601 - val_mse: 0.0370\n",
      "Epoch 227/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0302 - mse: 0.0072 - val_loss: 0.0593 - val_mse: 0.0363\n",
      "Epoch 228/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0064 - val_loss: 0.0693 - val_mse: 0.0467\n",
      "Epoch 229/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.0338 - mse: 0.0115\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0334 - mse: 0.0111 - val_loss: 0.0489 - val_mse: 0.0266\n",
      "Epoch 230/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0335 - mse: 0.0113 - val_loss: 0.0606 - val_mse: 0.0383\n",
      "Epoch 231/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0340 - mse: 0.0118 - val_loss: 0.0529 - val_mse: 0.0308\n",
      "Epoch 232/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0088 - val_loss: 0.0508 - val_mse: 0.0288\n",
      "Epoch 233/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0310 - mse: 0.0093 - val_loss: 0.0562 - val_mse: 0.0347\n",
      "Epoch 234/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0313 - mse: 0.0099 - val_loss: 0.0598 - val_mse: 0.0385\n",
      "Epoch 235/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0335 - mse: 0.0119 - val_loss: 0.0683 - val_mse: 0.0466\n",
      "Epoch 236/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0341 - mse: 0.0127 - val_loss: 0.0566 - val_mse: 0.0355\n",
      "Epoch 237/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0349 - mse: 0.0136 - val_loss: 0.0612 - val_mse: 0.0400\n",
      "Epoch 238/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0363 - mse: 0.0149 - val_loss: 0.0555 - val_mse: 0.0340\n",
      "Epoch 239/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0330 - mse: 0.0117 - val_loss: 0.0505 - val_mse: 0.0297\n",
      "Epoch 240/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 0.0160 - val_loss: 0.0529 - val_mse: 0.0321\n",
      "Epoch 241/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0148 - val_loss: 0.0669 - val_mse: 0.0461\n",
      "Epoch 242/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0101 - val_loss: 0.0601 - val_mse: 0.0405\n",
      "Epoch 243/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0093 - val_loss: 0.0556 - val_mse: 0.0364\n",
      "Epoch 244/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0113 - val_loss: 0.0531 - val_mse: 0.0341\n",
      "Epoch 245/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0097 - val_loss: 0.0479 - val_mse: 0.0287\n",
      "Epoch 246/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0274 - mse: 0.0085 - val_loss: 0.0509 - val_mse: 0.0321\n",
      "Epoch 247/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0094 - val_loss: 0.0456 - val_mse: 0.0273\n",
      "Epoch 248/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0264 - mse: 0.0084 - val_loss: 0.0485 - val_mse: 0.0307\n",
      "Epoch 249/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0089 - val_loss: 0.0588 - val_mse: 0.0412\n",
      "Epoch 250/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0096 - val_loss: 0.0517 - val_mse: 0.0344\n",
      "Epoch 251/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0265 - mse: 0.0091 - val_loss: 0.0493 - val_mse: 0.0321\n",
      "Epoch 252/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0096 - val_loss: 0.0465 - val_mse: 0.0295\n",
      "Epoch 253/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0115 - val_loss: 0.0478 - val_mse: 0.0307\n",
      "Epoch 254/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0264 - mse: 0.0094 - val_loss: 0.0502 - val_mse: 0.0333\n",
      "Epoch 255/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0090 - val_loss: 0.0545 - val_mse: 0.0377\n",
      "Epoch 256/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0240 - mse: 0.0075 - val_loss: 0.0549 - val_mse: 0.0387\n",
      "Epoch 257/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0240 - mse: 0.0079 - val_loss: 0.0442 - val_mse: 0.0283\n",
      "Epoch 258/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0302 - mse: 0.0140 - val_loss: 0.0642 - val_mse: 0.0479\n",
      "Epoch 259/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0323 - mse: 0.0152 - val_loss: 0.0553 - val_mse: 0.0375\n",
      "Epoch 260/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0177 - val_loss: 0.0634 - val_mse: 0.0450\n",
      "Epoch 261/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0360 - mse: 0.0170 - val_loss: 0.0523 - val_mse: 0.0325\n",
      "Epoch 262/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0356 - mse: 0.0150 - val_loss: 0.0567 - val_mse: 0.0362\n",
      "Epoch 263/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0109 - val_loss: 0.0483 - val_mse: 0.0312\n",
      "Epoch 264/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.0280 - mse: 0.0112\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0113 - val_loss: 0.0429 - val_mse: 0.0265\n",
      "Epoch 265/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0510 - val_mse: 0.0351\n",
      "Epoch 266/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0264 - mse: 0.0106 - val_loss: 0.0539 - val_mse: 0.0384\n",
      "Epoch 267/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0128 - val_loss: 0.0461 - val_mse: 0.0307\n",
      "Epoch 268/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0310 - mse: 0.0149 - val_loss: 0.0694 - val_mse: 0.0525\n",
      "Epoch 269/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0412 - mse: 0.0215 - val_loss: 0.0541 - val_mse: 0.0300\n",
      "Epoch 270/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0425 - mse: 0.0204 - val_loss: 0.0678 - val_mse: 0.0479\n",
      "Epoch 271/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0344 - mse: 0.0149 - val_loss: 0.0665 - val_mse: 0.0479\n",
      "Epoch 272/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0329 - mse: 0.0148 - val_loss: 0.0502 - val_mse: 0.0312\n",
      "Epoch 273/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0343 - mse: 0.0151 - val_loss: 0.0674 - val_mse: 0.0489\n",
      "Epoch 274/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0307 - mse: 0.0133 - val_loss: 0.0553 - val_mse: 0.0384\n",
      "Epoch 275/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0129 - val_loss: 0.0462 - val_mse: 0.0301\n",
      "Epoch 276/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0279 - mse: 0.0124 - val_loss: 0.0465 - val_mse: 0.0317\n",
      "Epoch 277/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0306 - mse: 0.0156 - val_loss: 0.0543 - val_mse: 0.0394\n",
      "Epoch 278/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0318 - mse: 0.0170 - val_loss: 0.0585 - val_mse: 0.0437\n",
      "Epoch 279/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0250 - mse: 0.0102 - val_loss: 0.0513 - val_mse: 0.0368\n",
      "Epoch 280/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0093 - val_loss: 0.0455 - val_mse: 0.0315\n",
      "Epoch 281/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0228 - mse: 0.0089 - val_loss: 0.0449 - val_mse: 0.0312\n",
      "Epoch 282/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0127 - val_loss: 0.0453 - val_mse: 0.0315\n",
      "Epoch 283/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0270 - mse: 0.0131 - val_loss: 0.0546 - val_mse: 0.0407\n",
      "Epoch 284/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0102 - val_loss: 0.0475 - val_mse: 0.0338\n",
      "Epoch 285/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0242 - mse: 0.0103 - val_loss: 0.0438 - val_mse: 0.0300\n",
      "Epoch 286/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0239 - mse: 0.0103 - val_loss: 0.0431 - val_mse: 0.0295\n",
      "Epoch 287/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0236 - mse: 0.0101 - val_loss: 0.0505 - val_mse: 0.0369\n",
      "Epoch 288/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0249 - mse: 0.0114 - val_loss: 0.0465 - val_mse: 0.0330\n",
      "Epoch 289/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0155 - val_loss: 0.0493 - val_mse: 0.0355\n",
      "Epoch 290/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0130 - val_loss: 0.0510 - val_mse: 0.0366\n",
      "Epoch 291/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0236 - mse: 0.0097 - val_loss: 0.0494 - val_mse: 0.0360\n",
      "Epoch 292/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0112 - val_loss: 0.0462 - val_mse: 0.0329\n",
      "Epoch 293/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0235 - mse: 0.0100 - val_loss: 0.0547 - val_mse: 0.0412\n",
      "Epoch 294/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0151 - val_loss: 0.0448 - val_mse: 0.0298\n",
      "Epoch 295/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0273 - mse: 0.0123 - val_loss: 0.0447 - val_mse: 0.0304\n",
      "Epoch 296/400\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 0.0241 - mse: 0.0102\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0098 - val_loss: 0.0400 - val_mse: 0.0262\n",
      "Epoch 297/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0246 - mse: 0.0114 - val_loss: 0.0450 - val_mse: 0.0321\n",
      "Epoch 298/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0264 - mse: 0.0130 - val_loss: 0.0434 - val_mse: 0.0298\n",
      "Epoch 299/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0120 - val_loss: 0.0407 - val_mse: 0.0274\n",
      "Epoch 300/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0234 - mse: 0.0103 - val_loss: 0.0445 - val_mse: 0.0315\n",
      "Epoch 301/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0088 - val_loss: 0.0432 - val_mse: 0.0309\n",
      "Epoch 302/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0204 - mse: 0.0082 - val_loss: 0.0559 - val_mse: 0.0437\n",
      "Epoch 303/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0217 - mse: 0.0098 - val_loss: 0.0424 - val_mse: 0.0304\n",
      "Epoch 304/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0115 - val_loss: 0.0445 - val_mse: 0.0320\n",
      "Epoch 305/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0238 - mse: 0.0114 - val_loss: 0.0515 - val_mse: 0.0389\n",
      "Epoch 306/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0225 - mse: 0.0102 - val_loss: 0.0405 - val_mse: 0.0283\n",
      "Epoch 307/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0245 - mse: 0.0125 - val_loss: 0.0618 - val_mse: 0.0496\n",
      "Epoch 308/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0222 - mse: 0.0101 - val_loss: 0.0485 - val_mse: 0.0363\n",
      "Epoch 309/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0214 - mse: 0.0093 - val_loss: 0.0435 - val_mse: 0.0316\n",
      "Epoch 310/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0106 - val_loss: 0.0448 - val_mse: 0.0331\n",
      "Epoch 311/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0122 - val_loss: 0.0592 - val_mse: 0.0476\n",
      "Epoch 312/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0228 - mse: 0.0107 - val_loss: 0.0549 - val_mse: 0.0426\n",
      "Epoch 313/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0106 - val_loss: 0.0567 - val_mse: 0.0447\n",
      "Epoch 314/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0115 - val_loss: 0.0505 - val_mse: 0.0386\n",
      "Epoch 315/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0107 - val_loss: 0.0433 - val_mse: 0.0315\n",
      "Epoch 316/400\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0274 - mse: 0.0154 - val_loss: 0.0694 - val_mse: 0.0555\n",
      "Epoch 317/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0171 - val_loss: 0.0615 - val_mse: 0.0474\n",
      "Epoch 318/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0113 - val_loss: 0.0479 - val_mse: 0.0348\n",
      "Epoch 319/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0137 - val_loss: 0.0707 - val_mse: 0.0583\n",
      "Epoch 320/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.0249 - mse: 0.0127\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0128 - val_loss: 0.0383 - val_mse: 0.0258\n",
      "Epoch 321/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0219 - mse: 0.0094 - val_loss: 0.0473 - val_mse: 0.0354\n",
      "Epoch 322/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0109 - val_loss: 0.0544 - val_mse: 0.0426\n",
      "Epoch 323/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0231 - mse: 0.0116 - val_loss: 0.0407 - val_mse: 0.0292\n",
      "Epoch 324/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0109 - val_loss: 0.0474 - val_mse: 0.0361\n",
      "Epoch 325/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0233 - mse: 0.0119 - val_loss: 0.0504 - val_mse: 0.0388\n",
      "Epoch 326/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0101 - val_loss: 0.0502 - val_mse: 0.0390\n",
      "Epoch 327/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0135 - val_loss: 0.0425 - val_mse: 0.0312\n",
      "Epoch 328/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0118 - val_loss: 0.0417 - val_mse: 0.0302\n",
      "Epoch 329/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0120 - val_loss: 0.0454 - val_mse: 0.0346\n",
      "Epoch 330/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0196 - mse: 0.0088 - val_loss: 0.0393 - val_mse: 0.0289\n",
      "Epoch 331/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0094 - val_loss: 0.0557 - val_mse: 0.0453\n",
      "Epoch 332/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0151 - val_loss: 0.0546 - val_mse: 0.0433\n",
      "Epoch 333/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0115 - val_loss: 0.0446 - val_mse: 0.0337\n",
      "Epoch 334/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0114 - val_loss: 0.0454 - val_mse: 0.0340\n",
      "Epoch 335/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0162 - val_loss: 0.0440 - val_mse: 0.0319\n",
      "Epoch 336/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0231 - mse: 0.0108 - val_loss: 0.0544 - val_mse: 0.0421\n",
      "Epoch 337/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0107 - val_loss: 0.0376 - val_mse: 0.0263\n",
      "Epoch 338/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0111 - val_loss: 0.0479 - val_mse: 0.0366\n",
      "Epoch 339/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0212 - mse: 0.0101 - val_loss: 0.0604 - val_mse: 0.0496\n",
      "Epoch 340/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0116 - val_loss: 0.0452 - val_mse: 0.0345\n",
      "Epoch 341/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0120 - val_loss: 0.0482 - val_mse: 0.0349\n",
      "Epoch 342/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0151 - val_loss: 0.0508 - val_mse: 0.0371\n",
      "Epoch 343/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0130 - val_loss: 0.0442 - val_mse: 0.0314\n",
      "Epoch 344/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0115 - val_loss: 0.0567 - val_mse: 0.0451\n",
      "Epoch 345/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0250 - mse: 0.0136 - val_loss: 0.0387 - val_mse: 0.0279\n",
      "Epoch 346/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0316 - mse: 0.0205 - val_loss: 0.0550 - val_mse: 0.0433\n",
      "Epoch 347/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0131 - val_loss: 0.0474 - val_mse: 0.0364\n",
      "Epoch 348/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0114 - val_loss: 0.0465 - val_mse: 0.0358\n",
      "Epoch 349/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0154 - val_loss: 0.0528 - val_mse: 0.0407\n",
      "Epoch 350/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0128 - val_loss: 0.0461 - val_mse: 0.0350\n",
      "Epoch 351/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0090 - val_loss: 0.0408 - val_mse: 0.0304\n",
      "Epoch 352/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0125 - val_loss: 0.0384 - val_mse: 0.0283\n",
      "Epoch 353/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0280 - mse: 0.0175 - val_loss: 0.0433 - val_mse: 0.0324\n",
      "Epoch 354/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0249 - mse: 0.0131 - val_loss: 0.0506 - val_mse: 0.0382\n",
      "Epoch 355/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0232 - mse: 0.0116 - val_loss: 0.0573 - val_mse: 0.0465\n",
      "Epoch 356/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0192 - mse: 0.0089 - val_loss: 0.0358 - val_mse: 0.0258\n",
      "Epoch 357/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0131 - val_loss: 0.0429 - val_mse: 0.0328\n",
      "Epoch 358/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0138 - val_loss: 0.0553 - val_mse: 0.0448\n",
      "Epoch 359/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0246 - mse: 0.0139 - val_loss: 0.0445 - val_mse: 0.0335\n",
      "Epoch 360/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0129 - val_loss: 0.0411 - val_mse: 0.0300\n",
      "Epoch 361/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0093 - val_loss: 0.0436 - val_mse: 0.0337\n",
      "Epoch 362/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0226 - mse: 0.0126 - val_loss: 0.0360 - val_mse: 0.0259\n",
      "Epoch 363/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0102 - val_loss: 0.0472 - val_mse: 0.0367\n",
      "Epoch 364/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0109 - val_loss: 0.0466 - val_mse: 0.0366\n",
      "Epoch 365/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0114 - val_loss: 0.0438 - val_mse: 0.0336\n",
      "Epoch 366/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.0196 - mse: 0.0095\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0093 - val_loss: 0.0347 - val_mse: 0.0249\n",
      "Epoch 367/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0222 - mse: 0.0122 - val_loss: 0.0452 - val_mse: 0.0350\n",
      "Epoch 368/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 0.0119 - val_loss: 0.0421 - val_mse: 0.0324\n",
      "Epoch 369/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0161 - val_loss: 0.0466 - val_mse: 0.0360\n",
      "Epoch 370/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0204 - mse: 0.0100 - val_loss: 0.0423 - val_mse: 0.0327\n",
      "Epoch 371/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0100 - val_loss: 0.0396 - val_mse: 0.0296\n",
      "Epoch 372/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0097 - val_loss: 0.0406 - val_mse: 0.0309\n",
      "Epoch 373/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0100 - val_loss: 0.0390 - val_mse: 0.0297\n",
      "Epoch 374/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0110 - val_loss: 0.0465 - val_mse: 0.0370\n",
      "Epoch 375/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0110 - val_loss: 0.0548 - val_mse: 0.0453\n",
      "Epoch 376/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0123 - val_loss: 0.0588 - val_mse: 0.0489\n",
      "Epoch 377/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0155 - val_loss: 0.0469 - val_mse: 0.0368\n",
      "Epoch 378/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0214 - mse: 0.0110 - val_loss: 0.0356 - val_mse: 0.0256\n",
      "Epoch 379/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0217 - mse: 0.0120 - val_loss: 0.0373 - val_mse: 0.0274\n",
      "Epoch 380/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0118 - val_loss: 0.0356 - val_mse: 0.0252\n",
      "Epoch 381/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0112 - val_loss: 0.0450 - val_mse: 0.0353\n",
      "Epoch 382/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0202 - mse: 0.0106 - val_loss: 0.0471 - val_mse: 0.0376\n",
      "Epoch 383/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0232 - mse: 0.0130 - val_loss: 0.0397 - val_mse: 0.0290\n",
      "Epoch 384/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0111 - val_loss: 0.0407 - val_mse: 0.0310\n",
      "Epoch 385/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0099 - val_loss: 0.0410 - val_mse: 0.0314\n",
      "Epoch 386/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0190 - mse: 0.0097 - val_loss: 0.0515 - val_mse: 0.0421\n",
      "Epoch 387/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 0.0096 - val_loss: 0.0379 - val_mse: 0.0287\n",
      "Epoch 388/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0128 - val_loss: 0.0467 - val_mse: 0.0375\n",
      "Epoch 389/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0150 - val_loss: 0.0458 - val_mse: 0.0357\n",
      "Epoch 390/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0207 - mse: 0.0105 - val_loss: 0.0417 - val_mse: 0.0319\n",
      "Epoch 391/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0095 - val_loss: 0.0368 - val_mse: 0.0273\n",
      "Epoch 392/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0089 - val_loss: 0.0356 - val_mse: 0.0262\n",
      "Epoch 393/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0191 - mse: 0.0097 - val_loss: 0.0447 - val_mse: 0.0355\n",
      "Epoch 394/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.0181 - mse: 0.0089\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0095 - val_loss: 0.0338 - val_mse: 0.0246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0195 - mse: 0.0103 - val_loss: 0.0365 - val_mse: 0.0274\n",
      "Epoch 396/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0219 - mse: 0.0126 - val_loss: 0.0534 - val_mse: 0.0437\n",
      "Epoch 397/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0133 - val_loss: 0.0398 - val_mse: 0.0299\n",
      "Epoch 398/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0087 - val_loss: 0.0398 - val_mse: 0.0307\n",
      "Epoch 399/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0094 - val_loss: 0.0429 - val_mse: 0.0336\n",
      "Epoch 400/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0102 - val_loss: 0.0388 - val_mse: 0.0295\n",
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81574/1592310825.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  weights[model_idx] = np.array(save_best_model.best_weights) / n_trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/37 [====================>.........] - ETA: 0s - loss: 35.9748 - mse: 20.4504   \n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 1s 5ms/step - loss: 31.8202 - mse: 16.3567 - val_loss: 19.9496 - val_mse: 4.7647\n",
      "Epoch 2/400\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 17.3006 - mse: 2.4473\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 17.0607 - mse: 2.2713 - val_loss: 16.8085 - val_mse: 2.4664\n",
      "Epoch 3/400\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 14.8253 - mse: 0.8510\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 14.7503 - mse: 0.8438 - val_loss: 15.4520 - val_mse: 2.0214\n",
      "Epoch 4/400\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 13.8609 - mse: 0.7983\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13.8057 - mse: 0.8091 - val_loss: 14.1866 - val_mse: 1.6526\n",
      "Epoch 5/400\n",
      "28/37 [=====================>........] - ETA: 0s - loss: 12.9186 - mse: 0.7020\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12.7907 - mse: 0.6725 - val_loss: 12.9288 - val_mse: 1.2528\n",
      "Epoch 6/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 11.9600 - mse: 0.6798 - val_loss: 12.7476 - val_mse: 1.8884\n",
      "Epoch 7/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 11.1546 - mse: 0.6688 - val_loss: 11.6639 - val_mse: 1.5723\n",
      "Epoch 8/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10.5847 - mse: 0.8395 - val_loss: 11.7403 - val_mse: 2.3623\n",
      "Epoch 9/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10.5435 - mse: 1.4725 - val_loss: 10.0942 - val_mse: 1.3382\n",
      "Epoch 10/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 9.4952 - mse: 1.0297 - val_loss: 9.7689 - val_mse: 1.6051\n",
      "Epoch 11/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 8.8268 - mse: 0.9321 - val_loss: 9.0885 - val_mse: 1.4852\n",
      "Epoch 12/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 8.0086 - mse: 0.6621 - val_loss: 8.5753 - val_mse: 1.5044\n",
      "Epoch 13/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 7.3222 - mse: 0.4455\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 7.2856 - mse: 0.4608 - val_loss: 7.7930 - val_mse: 1.2317\n",
      "Epoch 14/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 6.7229 - mse: 0.3931 - val_loss: 7.3959 - val_mse: 1.3068\n",
      "Epoch 15/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 6.4335 - mse: 0.5136\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 6.3566 - mse: 0.4795 - val_loss: 6.7421 - val_mse: 1.0865\n",
      "Epoch 16/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 6.0084 - mse: 0.5429 - val_loss: 6.5158 - val_mse: 1.2486\n",
      "Epoch 17/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 5.8497 - mse: 0.7540 - val_loss: 6.1932 - val_mse: 1.2710\n",
      "Epoch 18/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5.4624 - mse: 0.6960 - val_loss: 6.3842 - val_mse: 1.7810\n",
      "Epoch 19/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5.1512 - mse: 0.6907 - val_loss: 5.5700 - val_mse: 1.2578\n",
      "Epoch 20/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.8884 - mse: 0.7089 - val_loss: 5.8768 - val_mse: 1.8323\n",
      "Epoch 21/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.6266 - mse: 0.6997 - val_loss: 5.0359 - val_mse: 1.2329\n",
      "Epoch 22/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.7882 - mse: 1.0949 - val_loss: 4.9972 - val_mse: 1.4050\n",
      "Epoch 23/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.3723 - mse: 0.8717 - val_loss: 4.6174 - val_mse: 1.2104\n",
      "Epoch 24/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4.1130 - mse: 0.8046 - val_loss: 4.7276 - val_mse: 1.5188\n",
      "Epoch 25/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3.6505 - mse: 0.5365 - val_loss: 4.1243 - val_mse: 1.1095\n",
      "Epoch 26/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3.3851 - mse: 0.4584 - val_loss: 4.2149 - val_mse: 1.3813\n",
      "Epoch 27/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 3.2213 - mse: 0.4518\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3.2345 - mse: 0.4817 - val_loss: 3.5895 - val_mse: 0.9191\n",
      "Epoch 28/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3.0948 - mse: 0.4925 - val_loss: 4.1485 - val_mse: 1.6197\n",
      "Epoch 29/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3.1681 - mse: 0.6970 - val_loss: 3.7365 - val_mse: 1.3269\n",
      "Epoch 30/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3.2409 - mse: 0.8817 - val_loss: 3.8157 - val_mse: 1.5069\n",
      "Epoch 31/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2.8767 - mse: 0.6187 - val_loss: 3.2191 - val_mse: 1.0225\n",
      "Epoch 32/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2.7328 - mse: 0.5908 - val_loss: 3.2856 - val_mse: 1.2026\n",
      "Epoch 33/400\n",
      "28/37 [=====================>........] - ETA: 0s - loss: 2.4518 - mse: 0.4121\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2.4448 - mse: 0.4186 - val_loss: 2.8696 - val_mse: 0.9064\n",
      "Epoch 34/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2.2996 - mse: 0.3852 - val_loss: 2.8087 - val_mse: 0.9466\n",
      "Epoch 35/400\n",
      "28/37 [=====================>........] - ETA: 0s - loss: 2.2030 - mse: 0.3806\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2.1593 - mse: 0.3489 - val_loss: 2.6134 - val_mse: 0.8574\n",
      "Epoch 36/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2.0607 - mse: 0.3500 - val_loss: 2.7802 - val_mse: 1.1169\n",
      "Epoch 37/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2.0020 - mse: 0.3818 - val_loss: 2.5029 - val_mse: 0.9244\n",
      "Epoch 38/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.9584 - mse: 0.4155 - val_loss: 2.7732 - val_mse: 1.2645\n",
      "Epoch 39/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.9416 - mse: 0.4659 - val_loss: 2.3549 - val_mse: 0.9091\n",
      "Epoch 40/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 2.0132 - mse: 0.5904\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.9641 - mse: 0.5464 - val_loss: 2.2071 - val_mse: 0.8179\n",
      "Epoch 41/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.8558 - mse: 0.4945 - val_loss: 2.2471 - val_mse: 0.9134\n",
      "Epoch 42/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.7359 - mse: 0.4283 - val_loss: 2.7286 - val_mse: 1.4525\n",
      "Epoch 43/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.8697 - mse: 0.6105 - val_loss: 2.2408 - val_mse: 0.9961\n",
      "Epoch 44/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.8012 - mse: 0.5793 - val_loss: 2.2352 - val_mse: 1.0365\n",
      "Epoch 45/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.5718 - mse: 0.3954 - val_loss: 2.1053 - val_mse: 0.9560\n",
      "Epoch 46/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.4328 - mse: 0.3112 - val_loss: 2.2695 - val_mse: 1.1764\n",
      "Epoch 47/400\n",
      "28/37 [=====================>........] - ETA: 0s - loss: 1.5427 - mse: 0.4687\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.4997 - mse: 0.4307 - val_loss: 1.7059 - val_mse: 0.6597\n",
      "Epoch 48/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.4102 - mse: 0.3863 - val_loss: 1.9253 - val_mse: 0.9220\n",
      "Epoch 49/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.3571 - mse: 0.3742 - val_loss: 1.7840 - val_mse: 0.8169\n",
      "Epoch 50/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.2880 - mse: 0.3398 - val_loss: 1.8472 - val_mse: 0.9172\n",
      "Epoch 51/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.1856 - mse: 0.2778 - val_loss: 1.8831 - val_mse: 0.9939\n",
      "Epoch 52/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.2892 - mse: 0.4176 - val_loss: 2.1468 - val_mse: 1.2904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.2175 - mse: 0.3754 - val_loss: 1.6012 - val_mse: 0.7739\n",
      "Epoch 54/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.2020 - mse: 0.3895 - val_loss: 1.7262 - val_mse: 0.9270\n",
      "Epoch 55/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.1240 - mse: 0.3379 - val_loss: 1.5532 - val_mse: 0.7840\n",
      "Epoch 56/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.0530 - mse: 0.2944 - val_loss: 1.5749 - val_mse: 0.8321\n",
      "Epoch 57/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9913 - mse: 0.2627 - val_loss: 1.4054 - val_mse: 0.6922\n",
      "Epoch 58/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9443 - mse: 0.2453 - val_loss: 1.7523 - val_mse: 1.0677\n",
      "Epoch 59/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.0076 - mse: 0.3341 - val_loss: 1.4374 - val_mse: 0.7746\n",
      "Epoch 60/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9629 - mse: 0.3097 - val_loss: 1.5531 - val_mse: 0.9112\n",
      "Epoch 61/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.0659 - mse: 0.4294 - val_loss: 1.6785 - val_mse: 1.0465\n",
      "Epoch 62/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.1118 - mse: 0.4790 - val_loss: 1.6480 - val_mse: 1.0160\n",
      "Epoch 63/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9776 - mse: 0.3557 - val_loss: 1.6217 - val_mse: 1.0121\n",
      "Epoch 64/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9311 - mse: 0.3294 - val_loss: 1.5201 - val_mse: 0.9281\n",
      "Epoch 65/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8540 - mse: 0.2739 - val_loss: 1.2924 - val_mse: 0.7232\n",
      "Epoch 66/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9218 - mse: 0.3609 - val_loss: 1.3933 - val_mse: 0.8373\n",
      "Epoch 67/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.0512 - mse: 0.4958 - val_loss: 1.5818 - val_mse: 1.0211\n",
      "Epoch 68/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.1406 - mse: 0.5738 - val_loss: 1.8275 - val_mse: 1.2513\n",
      "Epoch 69/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.1535 - mse: 0.5596 - val_loss: 1.4424 - val_mse: 0.8389\n",
      "Epoch 70/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.0634 - mse: 0.4668 - val_loss: 1.3706 - val_mse: 0.7811\n",
      "Epoch 71/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.9075 - mse: 0.3239 - val_loss: 1.3187 - val_mse: 0.7430\n",
      "Epoch 72/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8245 - mse: 0.2634 - val_loss: 1.2308 - val_mse: 0.6830\n",
      "Epoch 73/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.7352 - mse: 0.1991\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.7697 - mse: 0.2372 - val_loss: 1.1134 - val_mse: 0.5965\n",
      "Epoch 74/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8575 - mse: 0.3506 - val_loss: 1.2285 - val_mse: 0.7271\n",
      "Epoch 75/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.0212 - mse: 0.5206 - val_loss: 1.3863 - val_mse: 0.8857\n",
      "Epoch 76/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.7978 - mse: 0.3066 - val_loss: 1.3912 - val_mse: 0.9084\n",
      "Epoch 77/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.7761 - mse: 0.3012 - val_loss: 1.0823 - val_mse: 0.6128\n",
      "Epoch 78/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6436 - mse: 0.1857 - val_loss: 1.3154 - val_mse: 0.8670\n",
      "Epoch 79/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6295 - mse: 0.1870 - val_loss: 1.0820 - val_mse: 0.6466\n",
      "Epoch 80/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5775 - mse: 0.1523 - val_loss: 1.1290 - val_mse: 0.7164\n",
      "Epoch 81/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5679 - mse: 0.1622 - val_loss: 1.0544 - val_mse: 0.6575\n",
      "Epoch 82/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6147 - mse: 0.2242 - val_loss: 1.0733 - val_mse: 0.6856\n",
      "Epoch 83/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.6054 - mse: 0.2225\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6039 - mse: 0.2219 - val_loss: 0.8984 - val_mse: 0.5208\n",
      "Epoch 84/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5345 - mse: 0.1647 - val_loss: 1.0489 - val_mse: 0.6883\n",
      "Epoch 85/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5569 - mse: 0.1982 - val_loss: 1.0219 - val_mse: 0.6686\n",
      "Epoch 86/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5339 - mse: 0.1878 - val_loss: 1.0606 - val_mse: 0.7193\n",
      "Epoch 87/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5689 - mse: 0.2298 - val_loss: 0.9087 - val_mse: 0.5718\n",
      "Epoch 88/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5750 - mse: 0.2376 - val_loss: 1.0698 - val_mse: 0.7331\n",
      "Epoch 89/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6301 - mse: 0.2925 - val_loss: 1.0146 - val_mse: 0.6691\n",
      "Epoch 90/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5894 - mse: 0.2461 - val_loss: 1.1002 - val_mse: 0.7619\n",
      "Epoch 91/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5261 - mse: 0.1939 - val_loss: 1.0261 - val_mse: 0.7006\n",
      "Epoch 92/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5190 - mse: 0.1984 - val_loss: 0.9844 - val_mse: 0.6680\n",
      "Epoch 93/400\n",
      "27/37 [====================>.........] - ETA: 0s - loss: 0.4725 - mse: 0.1596\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4580 - mse: 0.1467 - val_loss: 0.7774 - val_mse: 0.4713\n",
      "Epoch 94/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5154 - mse: 0.2165 - val_loss: 1.1666 - val_mse: 0.8709\n",
      "Epoch 95/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6105 - mse: 0.3151 - val_loss: 1.0124 - val_mse: 0.7148\n",
      "Epoch 96/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5444 - mse: 0.2503 - val_loss: 0.8666 - val_mse: 0.5768\n",
      "Epoch 97/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4005 - mse: 0.1171 - val_loss: 0.8298 - val_mse: 0.5544\n",
      "Epoch 98/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3483 - mse: 0.0796 - val_loss: 0.7402 - val_mse: 0.4798\n",
      "Epoch 99/400\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 0.3108 - mse: 0.0555\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3150 - mse: 0.0607 - val_loss: 0.6865 - val_mse: 0.4394\n",
      "Epoch 100/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2951 - mse: 0.0531 - val_loss: 0.7305 - val_mse: 0.4941\n",
      "Epoch 101/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.2710 - mse: 0.0392\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2830 - mse: 0.0521 - val_loss: 0.6337 - val_mse: 0.4072\n",
      "Epoch 102/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3118 - mse: 0.0893 - val_loss: 0.7630 - val_mse: 0.5442\n",
      "Epoch 103/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3231 - mse: 0.1077 - val_loss: 0.6859 - val_mse: 0.4739\n",
      "Epoch 104/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3551 - mse: 0.1436 - val_loss: 0.6591 - val_mse: 0.4476\n",
      "Epoch 105/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3511 - mse: 0.1414 - val_loss: 0.7288 - val_mse: 0.5206\n",
      "Epoch 106/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3978 - mse: 0.1890 - val_loss: 0.7053 - val_mse: 0.4940\n",
      "Epoch 107/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3801 - mse: 0.1654 - val_loss: 0.7959 - val_mse: 0.5747\n",
      "Epoch 108/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4071 - mse: 0.1845 - val_loss: 0.7236 - val_mse: 0.4929\n",
      "Epoch 109/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.7580 - mse: 0.4992 - val_loss: 0.9052 - val_mse: 0.6164\n",
      "Epoch 110/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8529 - mse: 0.5548 - val_loss: 0.9568 - val_mse: 0.6437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8345 - mse: 0.5028 - val_loss: 1.3106 - val_mse: 0.9488\n",
      "Epoch 112/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8872 - mse: 0.5294 - val_loss: 1.1784 - val_mse: 0.8241\n",
      "Epoch 113/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8070 - mse: 0.4468 - val_loss: 1.3917 - val_mse: 1.0329\n",
      "Epoch 114/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8528 - mse: 0.4994 - val_loss: 1.2200 - val_mse: 0.8645\n",
      "Epoch 115/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6246 - mse: 0.2646 - val_loss: 1.1113 - val_mse: 0.7679\n",
      "Epoch 116/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5836 - mse: 0.2599 - val_loss: 1.0515 - val_mse: 0.7495\n",
      "Epoch 117/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5116 - mse: 0.2141 - val_loss: 0.9101 - val_mse: 0.6221\n",
      "Epoch 118/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4223 - mse: 0.1453 - val_loss: 0.7786 - val_mse: 0.5157\n",
      "Epoch 119/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3699 - mse: 0.1151 - val_loss: 0.7734 - val_mse: 0.5293\n",
      "Epoch 120/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.3685 - mse: 0.1313\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3585 - mse: 0.1229 - val_loss: 0.6027 - val_mse: 0.3755\n",
      "Epoch 121/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3040 - mse: 0.0841 - val_loss: 0.6923 - val_mse: 0.4816\n",
      "Epoch 122/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3627 - mse: 0.1542 - val_loss: 0.6019 - val_mse: 0.3971\n",
      "Epoch 123/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3846 - mse: 0.1768 - val_loss: 0.7243 - val_mse: 0.5123\n",
      "Epoch 124/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3647 - mse: 0.1552 - val_loss: 0.6310 - val_mse: 0.4268\n",
      "Epoch 125/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2962 - mse: 0.0957 - val_loss: 0.6697 - val_mse: 0.4734\n",
      "Epoch 126/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.3022 - mse: 0.1085\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2943 - mse: 0.1015 - val_loss: 0.4941 - val_mse: 0.3062\n",
      "Epoch 127/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2406 - mse: 0.0590 - val_loss: 0.5535 - val_mse: 0.3781\n",
      "Epoch 128/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.2136 - mse: 0.0420\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2221 - mse: 0.0515 - val_loss: 0.4217 - val_mse: 0.2560\n",
      "Epoch 129/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2143 - mse: 0.0522 - val_loss: 0.5286 - val_mse: 0.3705\n",
      "Epoch 130/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.1930 - mse: 0.0375\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1910 - mse: 0.0361 - val_loss: 0.4067 - val_mse: 0.2554\n",
      "Epoch 131/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1797 - mse: 0.0316 - val_loss: 0.4886 - val_mse: 0.3439\n",
      "Epoch 132/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1765 - mse: 0.0343 - val_loss: 0.4021 - val_mse: 0.2625\n",
      "Epoch 133/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1734 - mse: 0.0364 - val_loss: 0.4806 - val_mse: 0.3464\n",
      "Epoch 134/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1744 - mse: 0.0419 - val_loss: 0.3861 - val_mse: 0.2558\n",
      "Epoch 135/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1648 - mse: 0.0366 - val_loss: 0.4789 - val_mse: 0.3530\n",
      "Epoch 136/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.1468 - mse: 0.0225\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1512 - mse: 0.0274 - val_loss: 0.3750 - val_mse: 0.2538\n",
      "Epoch 137/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1721 - mse: 0.0525 - val_loss: 0.5177 - val_mse: 0.3992\n",
      "Epoch 138/400\n",
      "28/37 [=====================>........] - ETA: 0s - loss: 0.1891 - mse: 0.0720\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1849 - mse: 0.0679 - val_loss: 0.3163 - val_mse: 0.1993\n",
      "Epoch 139/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2088 - mse: 0.0905 - val_loss: 0.4889 - val_mse: 0.3681\n",
      "Epoch 140/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1912 - mse: 0.0720 - val_loss: 0.3926 - val_mse: 0.2752\n",
      "Epoch 141/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2145 - mse: 0.0946 - val_loss: 0.4101 - val_mse: 0.2868\n",
      "Epoch 142/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2143 - mse: 0.0917 - val_loss: 0.3354 - val_mse: 0.2131\n",
      "Epoch 143/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2451 - mse: 0.1222 - val_loss: 0.4190 - val_mse: 0.2908\n",
      "Epoch 144/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2639 - mse: 0.1326 - val_loss: 0.4368 - val_mse: 0.3008\n",
      "Epoch 145/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2434 - mse: 0.1082 - val_loss: 0.4617 - val_mse: 0.3311\n",
      "Epoch 146/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2162 - mse: 0.0878 - val_loss: 0.3748 - val_mse: 0.2488\n",
      "Epoch 147/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1882 - mse: 0.0644 - val_loss: 0.3615 - val_mse: 0.2419\n",
      "Epoch 148/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1808 - mse: 0.0652 - val_loss: 0.4022 - val_mse: 0.2883\n",
      "Epoch 149/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2137 - mse: 0.0982 - val_loss: 0.4108 - val_mse: 0.2937\n",
      "Epoch 150/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1780 - mse: 0.0647 - val_loss: 0.3339 - val_mse: 0.2252\n",
      "Epoch 151/400\n",
      "28/37 [=====================>........] - ETA: 0s - loss: 0.1677 - mse: 0.0624\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1773 - mse: 0.0720 - val_loss: 0.2736 - val_mse: 0.1674\n",
      "Epoch 152/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1705 - mse: 0.0633 - val_loss: 0.3523 - val_mse: 0.2458\n",
      "Epoch 153/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2567 - mse: 0.1433 - val_loss: 0.4058 - val_mse: 0.2890\n",
      "Epoch 154/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2122 - mse: 0.0946 - val_loss: 0.4321 - val_mse: 0.3169\n",
      "Epoch 155/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2045 - mse: 0.0918 - val_loss: 0.3432 - val_mse: 0.2297\n",
      "Epoch 156/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2131 - mse: 0.1002 - val_loss: 0.4151 - val_mse: 0.3034\n",
      "Epoch 157/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2638 - mse: 0.1490 - val_loss: 0.3605 - val_mse: 0.2436\n",
      "Epoch 158/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2135 - mse: 0.0991 - val_loss: 0.3415 - val_mse: 0.2311\n",
      "Epoch 159/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1856 - mse: 0.0775 - val_loss: 0.2741 - val_mse: 0.1699\n",
      "Epoch 160/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1501 - mse: 0.0507 - val_loss: 0.4011 - val_mse: 0.3052\n",
      "Epoch 161/400\n",
      "28/37 [=====================>........] - ETA: 0s - loss: 0.1354 - mse: 0.0420\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1298 - mse: 0.0374 - val_loss: 0.2351 - val_mse: 0.1475\n",
      "Epoch 162/400\n",
      "26/37 [====================>.........] - ETA: 0s - loss: 0.1044 - mse: 0.0194\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1037 - mse: 0.0198 - val_loss: 0.2038 - val_mse: 0.1237\n",
      "Epoch 163/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.0941 - mse: 0.0164\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0944 - mse: 0.0172 - val_loss: 0.1918 - val_mse: 0.1172\n",
      "Epoch 164/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0902 - mse: 0.0175 - val_loss: 0.1909 - val_mse: 0.1201\n",
      "Epoch 165/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0818 - mse: 0.0128 - val_loss: 0.2099 - val_mse: 0.1427\n",
      "Epoch 166/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0791 - mse: 0.0133 - val_loss: 0.1854 - val_mse: 0.1209\n",
      "Epoch 167/400\n",
      "28/37 [=====================>........] - ETA: 0s - loss: 0.0751 - mse: 0.0117\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0741 - mse: 0.0110 - val_loss: 0.1709 - val_mse: 0.1090\n",
      "Epoch 168/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.0699 - mse: 0.0090\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0701 - mse: 0.0095 - val_loss: 0.1605 - val_mse: 0.1010\n",
      "Epoch 169/400\n",
      "27/37 [====================>.........] - ETA: 0s - loss: 0.0714 - mse: 0.0128\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0713 - mse: 0.0130 - val_loss: 0.1558 - val_mse: 0.0985\n",
      "Epoch 170/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0703 - mse: 0.0141 - val_loss: 0.1791 - val_mse: 0.1240\n",
      "Epoch 171/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0786 - mse: 0.0236 - val_loss: 0.1546 - val_mse: 0.1001\n",
      "Epoch 172/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0706 - mse: 0.0169 - val_loss: 0.1532 - val_mse: 0.1004\n",
      "Epoch 173/400\n",
      "27/37 [====================>.........] - ETA: 0s - loss: 0.0717 - mse: 0.0193\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0726 - mse: 0.0204 - val_loss: 0.1351 - val_mse: 0.0828\n",
      "Epoch 174/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1001 - mse: 0.0456 - val_loss: 0.1530 - val_mse: 0.0935\n",
      "Epoch 175/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1193 - mse: 0.0585 - val_loss: 0.1810 - val_mse: 0.1186\n",
      "Epoch 176/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1846 - mse: 0.1083 - val_loss: 0.2312 - val_mse: 0.1443\n",
      "Epoch 177/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2009 - mse: 0.1142 - val_loss: 0.3067 - val_mse: 0.2175\n",
      "Epoch 178/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1667 - mse: 0.0741 - val_loss: 0.2051 - val_mse: 0.1156\n",
      "Epoch 179/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.1110 - mse: 0.0294\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1091 - mse: 0.0297 - val_loss: 0.1453 - val_mse: 0.0760\n",
      "Epoch 180/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0977 - mse: 0.0328 - val_loss: 0.1579 - val_mse: 0.0962\n",
      "Epoch 181/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.0745 - mse: 0.0161\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0758 - mse: 0.0183 - val_loss: 0.1142 - val_mse: 0.0611\n",
      "Epoch 182/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.0629 - mse: 0.0118\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0618 - mse: 0.0112 - val_loss: 0.1073 - val_mse: 0.0591\n",
      "Epoch 183/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0554 - mse: 0.0089 - val_loss: 0.1160 - val_mse: 0.0712\n",
      "Epoch 184/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.0515 - mse: 0.0077\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0511 - mse: 0.0075 - val_loss: 0.0979 - val_mse: 0.0555\n",
      "Epoch 185/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0473 - mse: 0.0060 - val_loss: 0.0965 - val_mse: 0.0563\n",
      "Epoch 186/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.0460 - mse: 0.0063\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0063 - val_loss: 0.0910 - val_mse: 0.0523\n",
      "Epoch 187/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0436 - mse: 0.0056 - val_loss: 0.0908 - val_mse: 0.0536\n",
      "Epoch 188/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0417 - mse: 0.0050 - val_loss: 0.0902 - val_mse: 0.0541\n",
      "Epoch 189/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0434 - mse: 0.0078 - val_loss: 0.0958 - val_mse: 0.0607\n",
      "Epoch 190/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0431 - mse: 0.0084 - val_loss: 0.1178 - val_mse: 0.0834\n",
      "Epoch 191/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0445 - mse: 0.0105 - val_loss: 0.0988 - val_mse: 0.0652\n",
      "Epoch 192/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0426 - mse: 0.0093 - val_loss: 0.0928 - val_mse: 0.0599\n",
      "Epoch 193/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0408 - mse: 0.0083 - val_loss: 0.0931 - val_mse: 0.0611\n",
      "Epoch 194/400\n",
      "28/37 [=====================>........] - ETA: 0s - loss: 0.0447 - mse: 0.0129\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0438 - mse: 0.0120 - val_loss: 0.0837 - val_mse: 0.0521\n",
      "Epoch 195/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0422 - mse: 0.0108 - val_loss: 0.0849 - val_mse: 0.0537\n",
      "Epoch 196/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0401 - mse: 0.0092 - val_loss: 0.0878 - val_mse: 0.0572\n",
      "Epoch 197/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 0.0087 - val_loss: 0.0908 - val_mse: 0.0609\n",
      "Epoch 198/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.0387 - mse: 0.0090\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 0.0087 - val_loss: 0.0787 - val_mse: 0.0494\n",
      "Epoch 199/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0373 - mse: 0.0083 - val_loss: 0.0802 - val_mse: 0.0516\n",
      "Epoch 200/400\n",
      "28/37 [=====================>........] - ETA: 0s - loss: 0.0363 - mse: 0.0080\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0361 - mse: 0.0078 - val_loss: 0.0762 - val_mse: 0.0482\n",
      "Epoch 201/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0086 - val_loss: 0.0907 - val_mse: 0.0631\n",
      "Epoch 202/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0397 - mse: 0.0123 - val_loss: 0.0844 - val_mse: 0.0572\n",
      "Epoch 203/400\n",
      "28/37 [=====================>........] - ETA: 0s - loss: 0.0415 - mse: 0.0143\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0413 - mse: 0.0141 - val_loss: 0.0727 - val_mse: 0.0457\n",
      "Epoch 204/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0370 - mse: 0.0101 - val_loss: 0.0743 - val_mse: 0.0479\n",
      "Epoch 205/400\n",
      "28/37 [=====================>........] - ETA: 0s - loss: 0.0347 - mse: 0.0084\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0348 - mse: 0.0086 - val_loss: 0.0615 - val_mse: 0.0355\n",
      "Epoch 206/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0073 - val_loss: 0.0702 - val_mse: 0.0449\n",
      "Epoch 207/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0356 - mse: 0.0107 - val_loss: 0.0939 - val_mse: 0.0690\n",
      "Epoch 208/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0129 - val_loss: 0.0690 - val_mse: 0.0439\n",
      "Epoch 209/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0320 - mse: 0.0074 - val_loss: 0.0613 - val_mse: 0.0373\n",
      "Epoch 210/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0322 - mse: 0.0084 - val_loss: 0.0622 - val_mse: 0.0386\n",
      "Epoch 211/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0092 - val_loss: 0.0711 - val_mse: 0.0478\n",
      "Epoch 212/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.0331 - mse: 0.0099\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0337 - mse: 0.0105 - val_loss: 0.0557 - val_mse: 0.0326\n",
      "Epoch 213/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 0.0161 - val_loss: 0.0675 - val_mse: 0.0438\n",
      "Epoch 214/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0385 - mse: 0.0146 - val_loss: 0.0674 - val_mse: 0.0435\n",
      "Epoch 215/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 0.0138 - val_loss: 0.0633 - val_mse: 0.0392\n",
      "Epoch 216/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0362 - mse: 0.0127 - val_loss: 0.0571 - val_mse: 0.0341\n",
      "Epoch 217/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0396 - mse: 0.0165 - val_loss: 0.0753 - val_mse: 0.0511\n",
      "Epoch 218/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0363 - mse: 0.0124 - val_loss: 0.0581 - val_mse: 0.0353\n",
      "Epoch 219/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0331 - mse: 0.0108 - val_loss: 0.0580 - val_mse: 0.0362\n",
      "Epoch 220/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0151 - val_loss: 0.0717 - val_mse: 0.0504\n",
      "Epoch 221/400\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 0.0354 - mse: 0.0138\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0344 - mse: 0.0128 - val_loss: 0.0537 - val_mse: 0.0322\n",
      "Epoch 222/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0089 - val_loss: 0.0577 - val_mse: 0.0373\n",
      "Epoch 223/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0083 - val_loss: 0.0544 - val_mse: 0.0342\n",
      "Epoch 224/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0290 - mse: 0.0091 - val_loss: 0.0587 - val_mse: 0.0390\n",
      "Epoch 225/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0108 - val_loss: 0.0604 - val_mse: 0.0405\n",
      "Epoch 226/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0324 - mse: 0.0127 - val_loss: 0.0725 - val_mse: 0.0531\n",
      "Epoch 227/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0369 - mse: 0.0171 - val_loss: 0.0529 - val_mse: 0.0325\n",
      "Epoch 228/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0340 - mse: 0.0136 - val_loss: 0.0853 - val_mse: 0.0652\n",
      "Epoch 229/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0342 - mse: 0.0143 - val_loss: 0.0614 - val_mse: 0.0414\n",
      "Epoch 230/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0416 - mse: 0.0209 - val_loss: 0.0741 - val_mse: 0.0529\n",
      "Epoch 231/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0385 - mse: 0.0171 - val_loss: 0.0614 - val_mse: 0.0391\n",
      "Epoch 232/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0352 - mse: 0.0136 - val_loss: 0.0617 - val_mse: 0.0413\n",
      "Epoch 233/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0323 - mse: 0.0119 - val_loss: 0.0597 - val_mse: 0.0397\n",
      "Epoch 234/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.0282 - mse: 0.0089\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0091 - val_loss: 0.0500 - val_mse: 0.0315\n",
      "Epoch 235/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0278 - mse: 0.0098 - val_loss: 0.0573 - val_mse: 0.0394\n",
      "Epoch 236/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.0290 - mse: 0.0110\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0108 - val_loss: 0.0490 - val_mse: 0.0310\n",
      "Epoch 237/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0097 - val_loss: 0.0511 - val_mse: 0.0335\n",
      "Epoch 238/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0280 - mse: 0.0107 - val_loss: 0.0528 - val_mse: 0.0355\n",
      "Epoch 239/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.0267 - mse: 0.0095\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0095 - val_loss: 0.0453 - val_mse: 0.0284\n",
      "Epoch 240/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0103 - val_loss: 0.0614 - val_mse: 0.0439\n",
      "Epoch 241/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0112 - val_loss: 0.0711 - val_mse: 0.0543\n",
      "Epoch 242/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0331 - mse: 0.0155 - val_loss: 0.0670 - val_mse: 0.0486\n",
      "Epoch 243/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0323 - mse: 0.0143 - val_loss: 0.0519 - val_mse: 0.0340\n",
      "Epoch 244/400\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.0304 - mse: 0.0123\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0308 - mse: 0.0126 - val_loss: 0.0442 - val_mse: 0.0263\n",
      "Epoch 245/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0313 - mse: 0.0135 - val_loss: 0.0534 - val_mse: 0.0357\n",
      "Epoch 246/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 0.0201 - val_loss: 0.0529 - val_mse: 0.0351\n",
      "Epoch 247/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0444 - mse: 0.0250 - val_loss: 0.0613 - val_mse: 0.0412\n",
      "Epoch 248/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0283 - val_loss: 0.0658 - val_mse: 0.0430\n",
      "Epoch 249/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0172 - val_loss: 0.0538 - val_mse: 0.0344\n",
      "Epoch 250/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0108 - val_loss: 0.0560 - val_mse: 0.0384\n",
      "Epoch 251/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0121 - val_loss: 0.0456 - val_mse: 0.0291\n",
      "Epoch 252/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0122 - val_loss: 0.0546 - val_mse: 0.0385\n",
      "Epoch 253/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0267 - mse: 0.0105 - val_loss: 0.0451 - val_mse: 0.0288\n",
      "Epoch 254/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0106 - val_loss: 0.0515 - val_mse: 0.0358\n",
      "Epoch 255/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0103 - val_loss: 0.0458 - val_mse: 0.0306\n",
      "Epoch 256/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0084 - val_loss: 0.0501 - val_mse: 0.0351\n",
      "Epoch 257/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0141 - val_loss: 0.0559 - val_mse: 0.0404\n",
      "Epoch 258/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0322 - mse: 0.0156 - val_loss: 0.0480 - val_mse: 0.0308\n",
      "Epoch 259/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0153 - val_loss: 0.0529 - val_mse: 0.0369\n",
      "Epoch 260/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0249 - mse: 0.0092 - val_loss: 0.0467 - val_mse: 0.0315\n",
      "Epoch 261/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0103 - val_loss: 0.0609 - val_mse: 0.0464\n",
      "Epoch 262/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0268 - mse: 0.0121 - val_loss: 0.0495 - val_mse: 0.0344\n",
      "Epoch 263/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0149 - val_loss: 0.0681 - val_mse: 0.0518\n",
      "Epoch 264/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0360 - mse: 0.0186 - val_loss: 0.0533 - val_mse: 0.0357\n",
      "Epoch 265/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0606 - mse: 0.0378 - val_loss: 0.0820 - val_mse: 0.0489\n",
      "Epoch 266/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0673 - mse: 0.0350 - val_loss: 0.0982 - val_mse: 0.0678\n",
      "Epoch 267/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0551 - mse: 0.0265 - val_loss: 0.0552 - val_mse: 0.0296\n",
      "Epoch 268/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0348 - mse: 0.0133 - val_loss: 0.0592 - val_mse: 0.0414\n",
      "Epoch 269/400\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.0282 - mse: 0.0113\n",
      "*****Saved as Best Model!*****\n",
      "\n",
      "\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0117 - val_loss: 0.0387 - val_mse: 0.0232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0242 - mse: 0.0095 - val_loss: 0.0439 - val_mse: 0.0298\n",
      "Epoch 271/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0220 - mse: 0.0083 - val_loss: 0.0381 - val_mse: 0.0247\n",
      "Epoch 272/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0105 - val_loss: 0.0500 - val_mse: 0.0367\n",
      "Epoch 273/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0213 - mse: 0.0081 - val_loss: 0.0451 - val_mse: 0.0319\n",
      "Epoch 274/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0224 - mse: 0.0093 - val_loss: 0.0441 - val_mse: 0.0313\n",
      "Epoch 275/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0097 - val_loss: 0.0444 - val_mse: 0.0315\n",
      "Epoch 276/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0258 - mse: 0.0127 - val_loss: 0.0450 - val_mse: 0.0317\n",
      "Epoch 277/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0098 - val_loss: 0.0503 - val_mse: 0.0373\n",
      "Epoch 278/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0125 - val_loss: 0.0487 - val_mse: 0.0357\n",
      "Epoch 279/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0104 - val_loss: 0.0419 - val_mse: 0.0288\n",
      "Epoch 280/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0225 - mse: 0.0096 - val_loss: 0.0546 - val_mse: 0.0419\n",
      "Epoch 281/400\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0222 - mse: 0.0096 - val_loss: 0.0503 - val_mse: 0.0380\n",
      "Epoch 282/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0156 - val_loss: 0.0549 - val_mse: 0.0414\n",
      "Epoch 283/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0319 - mse: 0.0177 - val_loss: 0.0541 - val_mse: 0.0395\n",
      "Epoch 284/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0278 - mse: 0.0129 - val_loss: 0.0497 - val_mse: 0.0344\n",
      "Epoch 285/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0101 - val_loss: 0.0487 - val_mse: 0.0347\n",
      "Epoch 286/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0249 - mse: 0.0111 - val_loss: 0.0383 - val_mse: 0.0249\n",
      "Epoch 287/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0100 - val_loss: 0.0433 - val_mse: 0.0306\n",
      "Epoch 288/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0080 - val_loss: 0.0403 - val_mse: 0.0282\n",
      "Epoch 289/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0210 - mse: 0.0089 - val_loss: 0.0440 - val_mse: 0.0318\n",
      "Epoch 290/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0101 - val_loss: 0.0476 - val_mse: 0.0358\n",
      "Epoch 291/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0101 - val_loss: 0.0487 - val_mse: 0.0365\n",
      "Epoch 292/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0264 - mse: 0.0141 - val_loss: 0.0562 - val_mse: 0.0439\n",
      "Epoch 293/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0127 - val_loss: 0.0552 - val_mse: 0.0425\n",
      "Epoch 294/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0087 - val_loss: 0.0430 - val_mse: 0.0312\n",
      "Epoch 295/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0087 - val_loss: 0.0434 - val_mse: 0.0317\n",
      "Epoch 296/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0086 - val_loss: 0.0449 - val_mse: 0.0332\n",
      "Epoch 297/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0261 - mse: 0.0142 - val_loss: 0.0478 - val_mse: 0.0356\n",
      "Epoch 298/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0143 - val_loss: 0.0475 - val_mse: 0.0336\n",
      "Epoch 299/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0169 - val_loss: 0.0466 - val_mse: 0.0321\n",
      "Epoch 300/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0329 - mse: 0.0186 - val_loss: 0.0474 - val_mse: 0.0336\n",
      "Epoch 301/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0106 - val_loss: 0.0412 - val_mse: 0.0288\n",
      "Epoch 302/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0123 - val_loss: 0.0517 - val_mse: 0.0396\n",
      "Epoch 303/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0112 - val_loss: 0.0475 - val_mse: 0.0357\n",
      "Epoch 304/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0084 - val_loss: 0.0409 - val_mse: 0.0295\n",
      "Epoch 305/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0099 - val_loss: 0.0446 - val_mse: 0.0329\n",
      "Epoch 306/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0211 - mse: 0.0094 - val_loss: 0.0408 - val_mse: 0.0294\n",
      "Epoch 307/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0087 - val_loss: 0.0495 - val_mse: 0.0383\n",
      "Epoch 308/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0097 - val_loss: 0.0446 - val_mse: 0.0335\n",
      "Epoch 309/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0182 - val_loss: 0.0502 - val_mse: 0.0379\n",
      "Epoch 310/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0111 - val_loss: 0.0464 - val_mse: 0.0348\n",
      "Epoch 311/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0082 - val_loss: 0.0478 - val_mse: 0.0368\n",
      "Epoch 312/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0093 - val_loss: 0.0428 - val_mse: 0.0319\n",
      "Epoch 313/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0113 - val_loss: 0.0413 - val_mse: 0.0299\n",
      "Epoch 314/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0092 - val_loss: 0.0519 - val_mse: 0.0407\n",
      "Epoch 315/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0092 - val_loss: 0.0484 - val_mse: 0.0374\n",
      "Epoch 316/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0220 - mse: 0.0108 - val_loss: 0.0513 - val_mse: 0.0405\n",
      "Epoch 317/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0105 - val_loss: 0.0415 - val_mse: 0.0303\n",
      "Epoch 318/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0208 - mse: 0.0099 - val_loss: 0.0435 - val_mse: 0.0327\n",
      "Epoch 319/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0137 - val_loss: 0.0462 - val_mse: 0.0351\n",
      "Epoch 320/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0097 - val_loss: 0.0433 - val_mse: 0.0321\n",
      "Epoch 321/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0132 - val_loss: 0.0552 - val_mse: 0.0437\n",
      "Epoch 322/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0124 - val_loss: 0.0501 - val_mse: 0.0387\n",
      "Epoch 323/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 0.0245 - val_loss: 0.0726 - val_mse: 0.0566\n",
      "Epoch 324/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0147 - val_loss: 0.0603 - val_mse: 0.0472\n",
      "Epoch 325/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0102 - val_loss: 0.0487 - val_mse: 0.0372\n",
      "Epoch 326/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0134 - val_loss: 0.0485 - val_mse: 0.0376\n",
      "Epoch 327/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0090 - val_loss: 0.0769 - val_mse: 0.0661\n",
      "Epoch 328/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0103 - val_loss: 0.0414 - val_mse: 0.0309\n",
      "Epoch 329/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0089 - val_loss: 0.0513 - val_mse: 0.0410\n",
      "Epoch 330/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0097 - val_loss: 0.0426 - val_mse: 0.0323\n",
      "Epoch 331/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0104 - val_loss: 0.0430 - val_mse: 0.0324\n",
      "Epoch 332/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0143 - val_loss: 0.0571 - val_mse: 0.0460\n",
      "Epoch 333/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0337 - mse: 0.0226 - val_loss: 0.0706 - val_mse: 0.0588\n",
      "Epoch 334/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0120 - val_loss: 0.0560 - val_mse: 0.0454\n",
      "Epoch 335/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0227 - mse: 0.0121 - val_loss: 0.0479 - val_mse: 0.0375\n",
      "Epoch 336/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0134 - val_loss: 0.0361 - val_mse: 0.0256\n",
      "Epoch 337/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0098 - val_loss: 0.0477 - val_mse: 0.0374\n",
      "Epoch 338/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0098 - val_loss: 0.0600 - val_mse: 0.0500\n",
      "Epoch 339/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0123 - val_loss: 0.0411 - val_mse: 0.0308\n",
      "Epoch 340/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0098 - val_loss: 0.0386 - val_mse: 0.0286\n",
      "Epoch 341/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0091 - val_loss: 0.0438 - val_mse: 0.0340\n",
      "Epoch 342/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0090 - val_loss: 0.0396 - val_mse: 0.0298\n",
      "Epoch 343/400\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0197 - mse: 0.0099 - val_loss: 0.0444 - val_mse: 0.0346\n",
      "Epoch 344/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0095 - val_loss: 0.0405 - val_mse: 0.0308\n",
      "Epoch 345/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0111 - val_loss: 0.0388 - val_mse: 0.0290\n",
      "Epoch 346/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0110 - val_loss: 0.0467 - val_mse: 0.0368\n",
      "Epoch 347/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0110 - val_loss: 0.0367 - val_mse: 0.0266\n",
      "Epoch 348/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0107 - val_loss: 0.0539 - val_mse: 0.0436\n",
      "Epoch 349/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0201 - mse: 0.0099 - val_loss: 0.0496 - val_mse: 0.0396\n",
      "Epoch 350/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0111 - val_loss: 0.0532 - val_mse: 0.0428\n",
      "Epoch 351/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0103 - val_loss: 0.0422 - val_mse: 0.0322\n",
      "Epoch 352/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0120 - val_loss: 0.0471 - val_mse: 0.0369\n",
      "Epoch 353/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0125 - val_loss: 0.0384 - val_mse: 0.0283\n",
      "Epoch 354/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0106 - val_loss: 0.0423 - val_mse: 0.0326\n",
      "Epoch 355/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0100 - val_loss: 0.0377 - val_mse: 0.0278\n",
      "Epoch 356/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0110 - val_loss: 0.0406 - val_mse: 0.0305\n",
      "Epoch 357/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0121 - val_loss: 0.0442 - val_mse: 0.0338\n",
      "Epoch 358/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0123 - val_loss: 0.0482 - val_mse: 0.0373\n",
      "Epoch 359/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0113 - val_loss: 0.0491 - val_mse: 0.0385\n",
      "Epoch 360/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0210 - mse: 0.0109 - val_loss: 0.0377 - val_mse: 0.0282\n",
      "Epoch 361/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0091 - val_loss: 0.0396 - val_mse: 0.0301\n",
      "Epoch 362/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0104 - val_loss: 0.0394 - val_mse: 0.0299\n",
      "Epoch 363/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0102 - val_loss: 0.0513 - val_mse: 0.0416\n",
      "Epoch 364/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0207 - mse: 0.0112 - val_loss: 0.0420 - val_mse: 0.0323\n",
      "Epoch 365/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 0.0092 - val_loss: 0.0372 - val_mse: 0.0274\n",
      "Epoch 366/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0100 - val_loss: 0.0436 - val_mse: 0.0340\n",
      "Epoch 367/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0106 - val_loss: 0.0507 - val_mse: 0.0412\n",
      "Epoch 368/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0232 - mse: 0.0132 - val_loss: 0.0496 - val_mse: 0.0394\n",
      "Epoch 369/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0227 - mse: 0.0129 - val_loss: 0.0390 - val_mse: 0.0291\n",
      "Epoch 370/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0107 - val_loss: 0.0471 - val_mse: 0.0378\n",
      "Epoch 371/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0139 - val_loss: 0.0427 - val_mse: 0.0333\n",
      "Epoch 372/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0132 - val_loss: 0.0383 - val_mse: 0.0283\n",
      "Epoch 373/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0101 - val_loss: 0.0360 - val_mse: 0.0267\n",
      "Epoch 374/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 0.0096 - val_loss: 0.0555 - val_mse: 0.0464\n",
      "Epoch 375/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0176 - val_loss: 0.0465 - val_mse: 0.0362\n",
      "Epoch 376/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0184 - mse: 0.0088 - val_loss: 0.0381 - val_mse: 0.0289\n",
      "Epoch 377/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0104 - val_loss: 0.0458 - val_mse: 0.0367\n",
      "Epoch 378/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0205 - mse: 0.0112 - val_loss: 0.0380 - val_mse: 0.0287\n",
      "Epoch 379/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0090 - val_loss: 0.0436 - val_mse: 0.0343\n",
      "Epoch 380/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0096 - val_loss: 0.0467 - val_mse: 0.0378\n",
      "Epoch 381/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0127 - val_loss: 0.0456 - val_mse: 0.0360\n",
      "Epoch 382/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0342 - mse: 0.0241 - val_loss: 0.0451 - val_mse: 0.0337\n",
      "Epoch 383/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0310 - mse: 0.0188 - val_loss: 0.0438 - val_mse: 0.0323\n",
      "Epoch 384/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0204 - mse: 0.0101 - val_loss: 0.0410 - val_mse: 0.0316\n",
      "Epoch 385/400\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0121 - val_loss: 0.0406 - val_mse: 0.0314\n",
      "Epoch 386/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0219 - mse: 0.0126 - val_loss: 0.0408 - val_mse: 0.0311\n",
      "Epoch 387/400\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.0168 - mse: 0.0071"
     ]
    }
   ],
   "source": [
    "results, weights = eval_networks(X_train, y_train, [nn0], n_features, n_epochs=400, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yB8tDaMsoIVq"
   },
   "outputs": [],
   "source": [
    "model = nn0(n_features)\n",
    "model.set_weights(weights[0])\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jy_KBbCuy2D0"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(np.exp(pred), \n",
    "            index=range(1461, len(df)+1), \n",
    "            columns=['SalePrice']).reset_index().\\\n",
    "                rename(columns={'index': 'id'}).\\\n",
    "                    to_csv(f'/content/sample_data/submissions/submission{suffix_out}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "house_prices_train.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
